{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\junior\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\junior\\anaconda3\\lib\\site-packages (from selenium) (1.24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class utilities:\n",
    "    \n",
    "    #def \n",
    "    \n",
    "    def wait(self, seconds):\n",
    "\n",
    "        s = np.random.normal(0, 1)\n",
    "        time.sleep(seconds*abs(s))\n",
    "    \n",
    "    def get_element_by_path(self, driver, xpath):\n",
    "        try:\n",
    "            return driver.find_element_by_xpath(xpath)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndeedItemParser:\n",
    "    def __init__(self):\n",
    "        self.driverPath = \"C:\\\\Users\\\\User\\\\Documents\\\\selenium\\\\driver\\\\chromedriver.exe\"\n",
    "        self.utilities = utilities();\n",
    "        \n",
    "    def _get_title(self, driver):\n",
    "        try:\n",
    "            title = driver.find_element_by_xpath(\"//*[@class='jobsearch-DesktopStickyContainer']//h3\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return title.text\n",
    "    \n",
    "    def _get_name(self, driver):\n",
    "        \n",
    "        try:    \n",
    "            name = driver.find_element_by_xpath(\"//*[contains(@class,'jobsearch-InlineCompanyRating')]//div[1]\")\n",
    "            return name.text\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "    \n",
    "    def _get_address(self,driver):\n",
    "         try:   \n",
    "            address = driver.find_element_by_xpath(\"//*[contains(@class,'jobsearch-InlineCompanyRating')]//div[3]\")\n",
    "            if address.text == \"-\":\n",
    "                address = driver.find_element_by_xpath(\"//*[contains(@class,'jobsearch-InlineCompanyRating')]//div[4]\")\n",
    "            return address.text\n",
    "         except Exception as e:\n",
    "            address = driver.find_element_by_xpath(\"//span[@class='jobsearch-JobMetadataHeader-iconLabel'][1]\")\n",
    "            return address.text\n",
    "    \n",
    "    def _get_salaire(self,driver, description):\n",
    "        #jobsearch-JobMetadataHeader-item \n",
    "        \"\"\"\n",
    "        pattern = r'[[S|s]alaire?[\\s+]?:?[\\s+]?(.*)?[\\s+]?|(.*)?[\\s+]?(par|\\/)?[\\s+]?(an|mois|jour|heure)'\n",
    "        text = description\n",
    "        try:\n",
    "            text = driver.find_element_by_xpath(\"//*[contains(@class,'jobsearch-JobMetadataHeader-item')]//span[1]\").text\n",
    "            print(\"first :\", text)\n",
    "            if text == \"\":\n",
    "                raise Exception(\"empty\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            try:   \n",
    "                text = driver.find_element_by_xpath(\"//*[contains(@class,'icl-IconFunctional--salary')]//*[contains(@class,'jobsearch-JobMetadataHeader-iconLabel')]\").text\n",
    "                print(\"second : \",text)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"troisi√®me\")\n",
    "                \n",
    "        outer = re.compile(pattern)\n",
    "        m = outer.search(text)\n",
    "        if m is not None:\n",
    "              return m.group(1)\n",
    "        return \"-\"\n",
    "        \"\"\"\n",
    "        return \"-\"\n",
    "            \n",
    "    \n",
    "    def _get_description(self,driver):\n",
    "        try:\n",
    "            #jobDescriptionText\n",
    "            e_description = driver.find_element_by_id(\"jobDescriptionText\")\n",
    "            return e_description.text\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    def _get_date(self,driver,url,name):\n",
    "       # print(url)\n",
    "        try:\n",
    "            date_str = driver.find_element_by_xpath(\"//*[@class='jobsearch-JobMetadataFooter']\")\n",
    "            date_str_full = date_str.text\n",
    "            date_tbl = date_str_full.split(\" \")\n",
    "            count_str = date_tbl[4]\n",
    "            label = date_tbl[5]\n",
    "            \n",
    "            if name in date_str_full:\n",
    "                date_str_full = date_str_full.replace(name, \"\")\n",
    "                date_tbl = date_str_full.split(\" \")\n",
    "                count_str = date_tbl[5]\n",
    "                label = date_tbl[6]\n",
    "                \n",
    "            if count_str == \"a\" :\n",
    "                count_str = date_tbl[5]\n",
    "                label = date_tbl[6]\n",
    "                \n",
    "            #print(\"date_str\", date_tbl)\n",
    "            date = datetime.now()\n",
    "            \n",
    "            if count_str == \"30+\":\n",
    "                return date - timedelta(days=30)\n",
    "            \n",
    "            count = int(count_str)\n",
    "            if \"jour\" in label:\n",
    "                date = date - timedelta(days=count)\n",
    "            elif \"heur\" in label:\n",
    "                date = date - timedelta(hours=count)\n",
    "            return date;\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    \n",
    "    def parse(self,url):\n",
    "        driver = webdriver.Chrome(self.driverPath)\n",
    "        driver.get(url)\n",
    "        driver.maximize_window()\n",
    "        \n",
    "        source = driver.page_source\n",
    "        title = self._get_title(driver)\n",
    "        name = self._get_name(driver)\n",
    "        address = self._get_address(driver)\n",
    "        date = self._get_date(driver, url,name)\n",
    "        description = self._get_description(driver)\n",
    "        salaire = self._get_salaire(driver,description)\n",
    "        \n",
    "        driver.quit()\n",
    "        \n",
    "        return title, name, address, date, salaire, description, source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item_parser = IndeedItemParser()\n",
    "#title, name, address, date, salaire,description,source = item_parser.parse(\"https://www.indeed.fr/voir-emploi?cmp=ECO--SI&t=Technicien+Support+Informatique&jk=dc1a032be2312c84&sjdu=QwrRXKrqZ3CNX5W-O9jEvX5ViC7ZmtCbUlpLMENSqzeEixTsazLVFu1bx1PMxHpgK0V934oVal0W7yYsbyobejEeYX4jvfhEEiUY8zoCrBk&tk=1dm9ttu0492gm801&adid=314524947&vjs=3\")\n",
    "#print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "import json\n",
    "\n",
    "class IndeedParserStateObject(object):\n",
    "    def __init__(self, data):\n",
    "        self.__dict__ = json.loads(data)\n",
    "        \n",
    "class IndeedParserStateHandler:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.filename = \"indeed.parser.state.json\"\n",
    "        self.object = self._load_file()\n",
    "        #self.object = IndeedParserStateObject(self.data)\n",
    "    \n",
    "    def save_state(self, job, location, page_request=\"\", page_item_index=-1):\n",
    "        self.object[\"job\"] = job\n",
    "        self.object[\"location\"] = location\n",
    "        self.object[\"page_request\"] = page_request\n",
    "        self.object[\"page_item_index\"]  = page_item_index\n",
    "        #self.data  = json.dumps(self.object)\n",
    "        \n",
    "        #data = json.dumps(self.object)\n",
    "        self._save_file(self.object)\n",
    "        #self.object = IndeedParserStateObject(self.data)\n",
    "        \n",
    "    def is_current_job(self, job):\n",
    "        if (self.object[\"job\"] == \"\") | (self.object[\"job\"] == job):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def is_current_location(self, location):\n",
    "        if (self.object[\"location\"] == \"\") | (self.object[\"location\"] == location):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def is_current_page_request(self, page_request):\n",
    "        if (self.object[\"page_request\"] == \"\") | (self.object[\"page_request\"] == page_request):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def _save_file(self, data):\n",
    "         with open(self.filename, 'w') as outfile:\n",
    "                json.dump(data, outfile)\n",
    "                \n",
    "    def _load_file(self):\n",
    "        \n",
    "        if path.exists(self.filename) == True:\n",
    "            with open(self.filename) as json_file:\n",
    "                data = json.load(json_file)\n",
    "        else:\n",
    "            data = {\n",
    "                     \"job\": \"\",\n",
    "                     \"location\":\"\",\n",
    "                     \"page_request\":\"\",\n",
    "                     \"page_item_index\":-1,\n",
    "                    }\n",
    "            with open(self.filename, 'w') as outfile:\n",
    "                json.dump(data, outfile)\n",
    "        \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os.path\n",
    "import os\n",
    "class IndeedPaser:\n",
    "    def __init__(self):\n",
    "        self.website = \"https://www.indeed.fr\"\n",
    "        self.driverPath = \"C:\\\\Users\\\\User\\\\Documents\\\\selenium\\\\driver\\\\chromedriver.exe\"\n",
    "        #self.dataset = pd.DataFrame(columns=['URL', 'Titre','Nom entreprise','Adresse','Date de publication', 'description'])\n",
    "        \n",
    "        if os.path.exists('indeed.csv') == True:\n",
    "            self.dataset = pd.read_csv(\"indeed.csv\")\n",
    "        else:\n",
    "            #URL,Titre,Nom entreprise,Adresse,Date de publication,salaire, description\n",
    "            self.dataset = pd.DataFrame(columns=['URL','Titre','Nom entreprise','Adresse','Date de publication','salaire','niveau experience', 'description'])\n",
    "        \n",
    "        self.jobs = [\"data scientist\", \"d√©veloppeur\", \"data analyst\", \"business intelligence\"]\n",
    "        self.locations = [\"Paris\",\"Lyon\", \"Toulouse\", \"Nantes\", \"Bordeaux\"]\n",
    "        #self.locations = [\"Paris\", \"Lyon\", \"Toulouse\", \"Nantes\", \"Bordeaux\"]\n",
    "        self.utilities =  utilities()\n",
    "        self.indeed_item_parser = IndeedItemParser()\n",
    "        self.parser_state = IndeedParserStateHandler()\n",
    "    \n",
    "    def _get_pages_counts(self,driver):\n",
    "        #searchCountPages\n",
    "        searchCountPages_elt = driver.find_element_by_id(\"searchCountPages\")\n",
    "        searchCountPages = searchCountPages_elt.text.split()\n",
    "        if len(searchCountPages) == 6:\n",
    "            searchCountPages = int(\"{0}{1}\".format(searchCountPages[3],searchCountPages[4])) \n",
    "        else :\n",
    "            searchCountPages = searchCountPages[3]  \n",
    "        \n",
    "        return (int(searchCountPages) // 18)\n",
    "    \n",
    "    def parse(self):\n",
    "        browser = webdriver.Chrome(self.driverPath)\n",
    "        browser.get(self.website)\n",
    "        browser.maximize_window()\n",
    "        \n",
    "        for job in self.jobs:\n",
    "            \n",
    "            #if self.parser_state.is_current_job(job) == False:\n",
    "            #    continue\n",
    "                    \n",
    "            for location in self.locations:\n",
    "                \n",
    "                #if self.parser_state.is_current_location(location) == False:\n",
    "                #    continue\n",
    "                #self.parser_state.save_state(job, location)\n",
    "                \n",
    "                query = \"https://www.indeed.fr/jobs?q={0}&l={1}\".format(job, location)\n",
    "                browser.get(query)\n",
    "                    \n",
    "                pages_count = self._get_pages_counts(browser)\n",
    "                \n",
    "                for page_index in range(1, pages_count):\n",
    "                    full_query = \"{0}&start={1}\".format(query,page_index)\n",
    "                    \n",
    "                    browser.get(full_query)\n",
    "                    \n",
    "                    items = browser.find_elements_by_xpath(\"//*[contains(@class,'clickcard')]\")\n",
    "                    dataset_len = len(self.dataset)\n",
    "                    \n",
    "                    for index_i,item in enumerate(items): \n",
    "                        title = item.find_element_by_xpath(\".//*[contains(@class,'jobtitle')]\")\n",
    "                        item_link = title.get_attribute(\"href\")\n",
    "                        \n",
    "                        try:\n",
    "                            if (self.dataset[\"URL\"].isin([item_link]).any()\n",
    "                                |\n",
    "                                (self.dataset[\"Titre\"].isin([item_link]).any()\n",
    "                                 &\n",
    "                                self.dataset[\"Nom entreprise\"].isin([item_link]).any()\n",
    "                                 & \n",
    "                                self.dataset[\"Adresse\"].isin([item_link]).any()\n",
    "                                 &\n",
    "                                self.dataset[\"description\"].isin([item_link]).any())\n",
    "                               ):\n",
    "                                print(\"parsed\", item_link)\n",
    "                            else:\n",
    "                                title, name, address, date,salaire, description, source = self.indeed_item_parser.parse(item_link)\n",
    "                                #self.dataset.loc[dataset_len + index_i] = [item_link, title, name, address, date, salaire, description]\n",
    "                                self.dataset.loc[dataset_len + index_i][\"URL\"] = item_link\n",
    "                                self.dataset.loc[dataset_len + index_i][\"Titre\"] = title\n",
    "                                self.dataset.loc[dataset_len + index_i][\"Nom entreprise\"] = name\n",
    "                                self.dataset.loc[dataset_len + index_i][\"Adresse\"] = address\n",
    "                                self.dataset.loc[dataset_len + index_i][\"Date de publication\"] = date\n",
    "                                self.dataset.loc[dataset_len + index_i][\"salaire\"] = salaire\n",
    "                                self.dataset.loc[dataset_len + index_i][\"description\"] = description\n",
    "                                \n",
    "                                #archivage des page html\n",
    "                                source_file_name = \"source_file.{0}.html\".format(dataset_len + index_i)\n",
    "                                if not os.path.exists(source_file_name):\n",
    "                                    file = open(\"pages/{0}\".format(source_file_name), \"w\")\n",
    "                                    source = item_link + \"----------------\" + source \n",
    "                                    file.write(source) \n",
    "                                    file.close() \n",
    "                                    \n",
    "                                print(\"len(dataset)\", len(self.dataset))\n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            #if (len(self.dataset) == 0) or (True not in self.dataset[\"URL\"].isin([item_link])):\n",
    "                        \n",
    "                        #break\n",
    "                    #break\n",
    "                    self.dataset.to_csv(\"indeed.csv\",index=False)\n",
    "                    #https://www.indeed.fr/jobs?q=developpeur&l=paris&start=10\n",
    "                #break\n",
    "            #break    \n",
    "            self.dataset.drop_duplicates(subset =\"URL\", keep = False, inplace = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-95d8a4475e97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIndeedPaser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-f181c006daa1>\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"parsed\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                                 \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msalaire\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindeed_item_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m                                 \u001b[1;31m#self.dataset.loc[dataset_len + index_i] = [item_link, title, name, address, date, salaire, description]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_len\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mindex_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"URL\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_link\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-f46ec5c955c2>\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriverPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mmaximize_window\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMAXIMIZE_WINDOW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'windowHandle'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'current'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfullscreen_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     70\u001b[0m             return self.request_encode_body(method, url, fields=fields,\n\u001b[0;32m     71\u001b[0m                                             \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                                             **urlopen_kw)\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     def request_encode_url(self, method, url, fields=None, headers=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = IndeedPaser()\n",
    "test.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3632"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/36/715c4ccace03a20cf7e8f15a670f651615744987af62fad8b48bea8f65f9/pymongo-3.9.0-cp37-cp37m-win_amd64.whl (351kB)\n",
      "Installing collected packages: pymongo\n",
      "Successfully installed pymongo-3.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting django\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/79/df0ffea7bf1e02c073c2633702c90f4384645c40a1dd09a308e02ef0c817/Django-2.2.6-py3-none-any.whl (7.5MB)\n",
      "Requirement already satisfied: pytz in c:\\users\\junior\\anaconda3\\lib\\site-packages (from django) (2018.9)\n",
      "Collecting sqlparse (from django)\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/53/900f7d2a54557c6a37886585a91336520e5539e3ae2423ff1102daf4f3a7/sqlparse-0.3.0-py2.py3-none-any.whl\n",
      "Installing collected packages: sqlparse, django\n",
      "Successfully installed django-2.2.6 sqlparse-0.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install django"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvToMongodbMigratorTool:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dataset = pd.read_csv(\"indeed.csv\")\n",
    "        self.mongodbdao = IndeedMongodbDao()\n",
    "        \n",
    "    def migrate(self):\n",
    "        records = json.loads(self.dataset.T.to_json()).values()\n",
    "        self.mongodbdao.insert_data_bulk(records)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#migratorTool = CsvToMongodbMigratorTool()\n",
    "#migratorTool.migrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient \n",
    "from pymongo import errors \n",
    "from django.core.validators import URLValidator\n",
    "from django.core.exceptions import ValidationError\n",
    "class IndeedMongodbDao:\n",
    "    def __init__(self):\n",
    "        self.conn = MongoClient() \n",
    "        self.db = self.conn.Indeed\n",
    "        self.collection = self.db.data\n",
    "        self._create_index()\n",
    "    \n",
    "    def _create_index(self):\n",
    "        index_name = 'url'\n",
    "        if index_name not in self.collection.index_information():\n",
    "            self.collection.create_index(index_name, unique=True)\n",
    "    \n",
    "    def _valid_url_format(self,url):\n",
    "        val = URLValidator()\n",
    "        try:\n",
    "            val(url)\n",
    "        except ValidationError as e:\n",
    "            raise Exception('bad format for url {}'.format(ur))\n",
    "    \n",
    "    def insert_data_bulk(self,data):\n",
    "        self.collection.insert_many(data)\n",
    "    \n",
    "    def insert_data(self, url, title, name, address, publication_date, description):\n",
    "        \n",
    "        try:\n",
    "            if url == \"\":\n",
    "                raise Exception('url cannot be empty {}'.format(ur))\n",
    "\n",
    "            self._valid_url_format(url)\n",
    "\n",
    "            if title == \"\":\n",
    "                raise Exception('title cannot be empty {}'.format(title))\n",
    "\n",
    "            if name == \"\":\n",
    "                raise Exception('the name of company cannot be be empty {}'.format(title))\n",
    "\n",
    "            if description == \"\":\n",
    "                raise Exception('description of company cannot be be empty {}'.format(title))\n",
    "\n",
    "\n",
    "            line_to_insert = {\n",
    "                                \"URL\": url,\n",
    "                                \"title\":title,\n",
    "                                \"name\":name,\n",
    "                                \"adresse\":address,\n",
    "                                \"publication_date\":publication_date,\n",
    "                                \"description\":description\n",
    "                             }\n",
    "\n",
    "            # Insert Data \n",
    "            result = self.collection.insert_one(line_to_insert) \n",
    "        except errors.DuplicateKeyError as e:\n",
    "            print('DuplicateKeyError : url {0} aready exist'.format(url))\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        data = self.collection.find({})\n",
    "        return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "class IndedRegexParser:\n",
    "    \n",
    "    def __init__(self, descriptif_text ):\n",
    "        self.descriptif_text = descriptif_text\n",
    "    \n",
    "    def _get_items(self,pattern):   \n",
    "        result_re = re.findall(pattern,self.descriptif_text)\n",
    "        result = []\n",
    "        for item_l_1 in result_re:\n",
    "            for item_l_2 in item_l_1:\n",
    "                if item_l_2 != \"\":\n",
    "                    result.append(item_l_2)\n",
    "        return result\n",
    "    \n",
    "    def _get_niveau_experience(self):\n",
    "        #Niveau d'exp√©rience : regex true\n",
    "        result = self._get_items('([(e|E)\\w+]xp√©rience?:?\\s\\d{1,15} ans?)|([(e|E)\\w+]xp√©rience?\\s?de\\s?\\d{1,15} ans?)|(\\d{1,15} ans d\\'[e|E]xp√©rience[s]?)')\n",
    "        if len(result) == 0:\n",
    "            outer = re.compile(r'Exp√©rience:\\s*.+:( (\\w) (an|ans) \\(((R|r)equis|(s|S)ouhait√©)\\))')\n",
    "            m = outer.search(self.descriptif_text)\n",
    "            if m is not None:\n",
    "                return m.group(1)\n",
    "            #return []\n",
    "    \n",
    "    def _get_salaires(self):\n",
    "        #Salaire ajust√© en fonction du co√ªt de la vie dans les diff√©rentes villes : regex true\n",
    "        #return self._get_items('(\\d{2,3}\\s?(k|K)?)|(\\d{2,3}\\s?\\d{3,5}\\s?(k|K)?)|([(s|S)]alaire?[\\s]?:?[\\s]?\\d{2,6}k?)|([(r|R)]√©mun√©ration?[\\s]?:?[\\s]?\\d{2,6}k?)|([(g|G)]ratification?[\\s]?:?[\\s]?\\d{2,6}k?)') \n",
    "        #[[S|s]alaire?[\\s+]?:?[\\s+]?(.*)e?[\\s+]?\\/an\n",
    "        outer = re.compile(r'[[S|s]alaire?[\\s+]?:?[\\s+]?(.*)e?[\\s+]?\\/(an|mois)|(.*)?[\\s+]?par?[\\s+]?mois')\n",
    "        m = outer.search(self.descriptif_text)\n",
    "        if m is not None:\n",
    "            return m.group(1)\n",
    "        return []\n",
    "            \n",
    "        \n",
    "    \n",
    "    def get_langages_prog(self):\n",
    "        #Langages de programmation requis (R, Python, Excel (VBA), SQL, C++, Java, SAS...): regex true\n",
    "        return self._get_items('(R+[^\\w])|([(p|P)\\w+]ython?)|(Excel?)|(VBA?)|(C\\+\\+?)||(C?)|(Asp.net?)|(SQL?)|(NoSQL?)|(Linux?)|(MySQL?)|(MongoDB?)|(DBMaria?)|(SQL Server?)||(Java?)|(JavaScript?)|(PHP?\\s?\\d{1,}?)|(HTML?\\s?\\d{1,}?)|(CSS?\\s?\\d{1,}?)|(SAS?)|(C#?)|(Ruby?)|(Swift?)|(Objective-C?)|(VB.NET?)|(Kotlin?)|(Scala?)|(Bash?)|(PowerShell?)|(Shell?)|(Front End?)|(Back End?)')\n",
    "    \n",
    "    def get_outils_re(self):\n",
    "        #Outils requis (Tableau, PowerBI...) : regex true\n",
    "        return self._get_items('([(t|T)\\w+]ableau?)|([(p|P)\\w+]ower[(b|B)\\w+][(i|I)\\w+]?)|([(s|S)\\w+]ymfony?\\s?\\d{1,}?)|([(j|J)\\w+][(q|Q)\\w+]uery?\\s?\\d{1,}?)|([(a|A)\\w+]ngular?[\\s?\\d{1,}]?)|([(r|R)\\w+]eact [(j|J)\\w+][(s|S)\\w+]?)|(React Native?)|(Node JS?)|([(g|G)\\w+]it?)|(Visual Studio?)|(Visual Studio Code?)|(Django?)|(Flask?)|(API REST?)|(http?s?)|(HTTP?S?)')\n",
    "        \n",
    "        \n",
    "    def get_niv_etudes_re(self):\n",
    "        #Niveau d'√©tudes requis : regex true\n",
    "        return self._get_items('([(f|F)\\w+]ormation?\\s?[(b|B)\\w+]ac\\s\\+\\s[1-8])|([(b|B)\\w+]ac\\s\\+\\s[1-8])')\n",
    "        \n",
    "    def get_type_cursus_re(self):\n",
    "        #Type de cursus (√©cole ing√©nieur, master, autodidacte...) : regex true\n",
    "        return self._get_items('([(√©|E)\\w+]cole [(i|I)\\w+]ng√©nieur?)|([(m|M)\\w+]aster?\\s?\\w{3,25})|([(a|A)\\w+]utodidacte?)|([(g|G)\\w+]rande[s]? [(√©|E)\\w+]cole[s]?)|([(√©|E)\\w+]cole[s]? de [(c|C)\\w+]ommerce[s]?)|([(i|I)\\w+]ng√©nieur [(i|I)\\w+]nformatique?)')\n",
    "        \n",
    "    def get_type_contrat_re(self):\n",
    "        #Type de contrat : regex true\n",
    "        return self._get_items('[(c|C)\\w+]ontrat?:?\\s\\w{3,25}')\n",
    "    \n",
    "    def get_categorie_developpeur_re(self):\n",
    "        #Grande cat√©gorie : d√©veloppeur (developeur web, dev mobile,dev) / data regex true\n",
    "        return self._get_items('([(d|D)\\w+]√©veloppeu[(r|s)]e? [(f|F)\\w+]ull? [(s|S)\\w+]tack)|([(d|D)\\w+]√©veloppeu[(r|s)]e? [(f|F)\\w+]ront[(\\s|\\-)][(e|E)\\w+]nd?)|(d√©veloppeu[(r|s)]e? Back[(\\s|\\-)][(e|E)\\w+]nd?)|([(d|D)\\w+]√©veloppeu[(r|s)]e? [(m|M)\\w+]obile?)|([(d|D)\\w+]√©veloppeu[(r|s)]e? [(l|L)\\w+]ogiciel?)|([(s|S)\\w+]oftware [(i|I)\\w+]ngenieer?)|([(d|D)\\w+]√©veloppeu[(r|s)]e? [(l|L)\\w+]ogiciels?)|([(d|D)\\w+]√©veloppeu[(r|s)]e? [(C|c)\\w+]\\+\\+?)|([(d|D)\\w+]√©veloppeu[(r|s)]e? [(c|C)\\w+]#?)|([(d|D)\\w+]√©veloppeu[(r|s)]e? [(j|J)\\w+]ava?)')\n",
    "    \n",
    "    def get_categorie_data_re(self):\n",
    "        #Grande cat√©gorie : data regex true\n",
    "        return self._get_items('([(d|D)\\w+]ata [(a|A)\\w+]nalyst?)|([(d|D)\\w+]ata [(s|S)\\w+]cientist?)|([(i|I)\\w+]ng√©nieu[(r|s)]e? [(m|M)\\w+]achine [(i|I)\\w+]earning?)|([(c|C)\\w+]onsultant [(b|B)\\w+]usiness [(i|I)\\w+]ntelligence)|([(c|C)\\w+]onsultant [(d|D)\\w+]ata)|([(c|C)\\w+]onsultant [(b|B)\\w+]ig [(d|D)\\w+]ata)|([(c|C)\\w+]onsultant BI)')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3632\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"indeed.csv\")\n",
    "print(len(dataset))\n",
    "#for index, row in dataset.iterrows():\n",
    "    #print(row[\"URL\"])\n",
    "    #indedRegexParser = IndedRegexParser(row[\"description\"])\n",
    "    #print(indedRegexParser._get_niveau_experience())\n",
    "    #print(indedRegexParser._get_salaires())\n",
    "    #print(indedRegexParser.get_outils_re())\n",
    "    #print(indedRegexParser.get_niv_etudes_re())\n",
    "    #print(indedRegexParser.get_type_cursus_re())\n",
    "    #print(indedRegexParser.get_type_contrat_re())\n",
    "    #print(indedRegexParser.get_categorie_developpeur_re())\n",
    "    #print(indedRegexParser.get_categorie_data_re())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URL', 'Titre', 'Nom entreprise', 'Adresse', 'Date de publication',\n",
       "       'salaire', 'description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"indeed.csv\")\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from orderedset import OrderedSet\n",
    "class LocalIndeedPaser:\n",
    "    def __init__(self):\n",
    "        self.pages_path = 'C:\\\\Users\\\\User\\\\Documents\\\\Projet_ML_gr3\\\\scrapping\\pages'\n",
    "        self.dataset = pd.read_csv(\"indeed.csv\")\n",
    "        self.salary_pattern = \"[[S|s]alaire?[\\s+]?:?[\\s+]?(.*)e?[\\s+]?\\/(an|mois)|((.*)?[\\s+]?par?[\\s+]?(an|ans|mois|jour|heure))\"\n",
    "    \n",
    "    def _get_salary(self,select_result):\n",
    "        salary = \"\"\n",
    "        for item in select_result:\n",
    "            if \"‚Ç¨\" in item.text:\n",
    "                outer_salary = re.compile(self.salary_pattern)\n",
    "                m_salary = outer_salary.search(item.text)\n",
    "                if m_salary is not None:\n",
    "                    salary = m_salary.group(0)\n",
    "                    break\n",
    "        return salary\n",
    "    \n",
    "    def save_file(self):\n",
    "        self.dataset.to_csv(\"indeed.csv\",index=False)\n",
    "    \n",
    "    def _get_listed_data(self, input_list):\n",
    "        data = []\n",
    "        for i in range(len(self.dataset)):\n",
    "            inside_data = []\n",
    "            for ele in input_list:\n",
    "                pattern = re.compile(r\"[\\s/\\(\\),]\"+ele+r\"[\\s/\\(\\),]\")\n",
    "                value = pattern.search(self.dataset['description'][i].lower().replace('\\n',' ').replace('\\r',' '))\n",
    "                if value:\n",
    "                    inside_data.append(1)\n",
    "                else:\n",
    "                    inside_data.append(0)\n",
    "            data.append(inside_data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def parse_langage(self):\n",
    "        languages = ['python', 'r','vba', 'mysql','excel','asp.net','nosql','sql','linux','mongodb',\n",
    "            'mariadb','java','javascript','php','html','css','sas','c#','ruby','swift','objective-c',\n",
    "            'vb.net','kotlin','scala','bash','powershell','shell','front end','back end','soap']\n",
    "        \n",
    "        data = self._get_listed_data(languages)\n",
    "        \n",
    "        language_dict = pd.DataFrame(data, columns=languages)\n",
    "        self.language_df = pd.DataFrame.from_dict(language_dict)\n",
    "        diff_cols = list(OrderedSet(self.dataset.columns) - OrderedSet(self.language_df.columns))\n",
    "        self.dataset = self.dataset[diff_cols]\n",
    "        self.dataset = pd.concat([self.dataset,self.language_df], axis=1)\n",
    "    \n",
    "    def parse_tools(self):\n",
    "        tools = ['tableau', 'powerbi','symfony', 'jquery','angular','react','react native','node js','git','github',\n",
    "            'visual studio','django','flask','api rest','laravel', 'hololens', 'docker', 'jira', 'scrum', 'kanban']\n",
    "        \n",
    "        data = self._get_listed_data(tools)\n",
    "\n",
    "        tools_dict = pd.DataFrame(data, columns=tools)\n",
    "        self.tools_df = pd.DataFrame.from_dict(tools_dict)\n",
    "        diff_cols = list(OrderedSet(self.dataset.columns) - OrderedSet(self.tools_df.columns))\n",
    "        self.dataset = self.dataset[diff_cols]\n",
    "        self.dataset = pd.concat([self.dataset,self.tools_df], axis=1)\n",
    "        \n",
    "    \n",
    "    def parse_salary(self):\n",
    "        index = 0\n",
    "        for root, dirs, files in os.walk(os.path.abspath(self.pages_path)):\n",
    "            for file in files:\n",
    "                local_file = os.path.join(root, file)\n",
    "                file = open(local_file, \"r\") \n",
    "                html = file.read() \n",
    "                outer = re.compile(r'.*\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-')\n",
    "                m = outer.search(html)\n",
    "                if m is not None:\n",
    "                    link = m.group(0).replace(\"----------------\",\"\")\n",
    "                    dataset_index = self.dataset[self.dataset[\"URL\"] == link].index.values.astype(int)\n",
    "                    #print(self.dataset[\"salaire\"][dataset_index].values[0])\n",
    "                    salary = self.dataset[\"salaire\"][dataset_index]\n",
    "                    \n",
    "                    if (len(salary.values) == 0):\n",
    "                        continue \n",
    "                        \n",
    "                    if (salary.values[0] != \"-\"):\n",
    "                        continue\n",
    "                        \n",
    "                    html = html.replace(m.group(0),\"\")\n",
    "                    soup = BeautifulSoup(html, \"html.parser\")\n",
    "                    result = soup.select(\".jobsearch-JobMetadataHeader-item\")\n",
    "                    if len(result) > 0:\n",
    "                        self.dataset[\"salaire\"][dataset_index] = self._get_salary(result)\n",
    "                        continue\n",
    "                        \n",
    "                    result = soup.select(\".jobsearch-JobMetadataHeader-itemWithIcon .jobsearch-JobMetadataHeader-iconLabel\")\n",
    "                    if len(result) > 0:\n",
    "                        self.dataset[\"salaire\"][dataset_index] = self._get_salary(result)\n",
    "                        continue\n",
    "                    \n",
    "                    result = soup.select(\"#jobDescriptionText\")\n",
    "                    if len(result) > 0:\n",
    "                        index = index + 1 \n",
    "                        outer_salary = re.compile(self.salary_pattern)\n",
    "                        m_salary = outer_salary.search(result[0].text)\n",
    "                        if m_salary is not None:\n",
    "                            salary = m_salary.group(0)\n",
    "                            print(salary)\n",
    "                            break\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "localIndeedPaser = LocalIndeedPaser()\n",
    "localIndeedPaser.parse_tools()\n",
    "localIndeedPaser.parse_langage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URL', 'Titre', 'Nom entreprise', 'Adresse', 'Date de publication',\n",
       "       'salaire', 'description', 'tableau', 'powerbi', 'symfony', 'jquery',\n",
       "       'angular', 'react', 'react native', 'node js', 'git', 'github',\n",
       "       'visual studio', 'django', 'flask', 'api rest', 'laravel', 'hololens',\n",
       "       'docker', 'jira', 'scrum', 'kanban', 'python', 'r', 'vba', 'mysql',\n",
       "       'excel', 'asp.net', 'nosql', 'sql', 'linux', 'mongodb', 'mariadb',\n",
       "       'java', 'javascript', 'php', 'html', 'css', 'sas', 'c#', 'ruby',\n",
       "       'swift', 'objective-c', 'vb.net', 'kotlin', 'scala', 'bash',\n",
       "       'powershell', 'shell', 'front end', 'back end', 'soap'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#localIndeedPaser.language_df\n",
    "localIndeedPaser.dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting orderedset\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/38/22cd720cd990b3154f5792e93965606f61b795c7da5901c7e79468b119e7/orderedset-2.0.1.tar.gz (95kB)\n",
      "Building wheels for collected packages: orderedset\n",
      "  Building wheel for orderedset (setup.py): started\n",
      "  Building wheel for orderedset (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Junior\\AppData\\Local\\pip\\Cache\\wheels\\68\\1a\\0a\\084d78f38459b3111414732e471b0cfbdf05b1931550f60ada\n",
      "Successfully built orderedset\n",
      "Installing collected packages: orderedset\n",
      "Successfully installed orderedset-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install orderedset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "localIndeedPaser.save_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYlbfkN0C5cUW69gWMagU3J5K1A_k01Vx9ltZoYwD7pptgAh3vLuJrZcHRVo6De2caH3Ort2lE6CgiOQWz6MGH2-A6pq2qoY9j86OzbwXgzXOxKY4gtptWN6wrWGMKCdwnMunrmFUWa1b4qMFgqsGZOoPYfhryqAalPWSpHwiewOGGYjBZysbv21AToMUnZ4BkANtbjLnbNuJaAQQiOw0k_9gXp_SH7g1L0J7jteMnxSlaW5Hv8c-mtBfNjnse7KGbemagx3qEvT2tTmd0X-KGH1KGoFg-6y477TtpQldV0JxQSxZ4wFN9y5vylvcphJJwuKs835iGwYy38X1jGKujH_jKv6diE-KS59h-w6DjlQWlvTDJcK5Afx7VqKOJrfLK4IkczilvjJUfCH2d3ATWrrJeSNquKTMXarhNP9DCiJ0GEOnYyBDaZ3hcPUhezK62SYTYho2M8eGnuthj6g==&p=4&fvj=1&vjs=3\n",
      "https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYlbfkN0C5cUW69gWMagU3J5K1A_k01Vx9ltZoYwD7pptgAh3vLuJrZcHRVo6De2caH3Ort2lE6CgiOQWz6MGH2-A6pq2qoY9j86OzbwXgzXOxKY4gtptWN6wrWGMKCdwnMunrmFUWa1b4qMFgqsGZOoPYfhryV53Jsbjl8UxGrhbYwUgHnnWMJv5rJ6lhnCu9m8rGa0NYMr8D73KOXz0nu6d0_ux8153VSBl8r23TKnsadeKTn29e2rBgAlLq3SBd-UTPd_w7kE7pyR1PwtMKguKDTmwJDXeFCamNxpL1zkwNTojC0XLaUSWyFT8OcBDc-MWw7nSCHbVZSUswN8IwOhTilh_dKYnTC8tlGdGJPW3xuxNDHbdX_tBnV_DZPZ01suUxUlZSXULHIqNDGyzIyrF-emR-84p9XqqrTrwoh-_9UaXseUrfy8p0bH9j2RmqLDo2Ay6meBwIJlzIXA==&p=5&fvj=1&vjs=3\n",
      "https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYlbfkN0C5cUW69gWMagU3J5K1A_k01Vx9ltZoYwD7pptgAh3vLuJrZcHRVo6De2caH3Ort2lE6CgiOQWz6MGH2-A6pq2qoY9j86OzbwXgzXOxKY4gtptWN6wrWGMKCdwnMunrmFUWa1b4qMFgqsGZOoPYfhryMITlZFCtfL-_LyECl2_QMH_Ze-4nB5O2E-oLUpy2C6HcZXgB2pNPP_QqTjCVXjybtoHMjv_HynOUWldqN7EzpSA4TUiIchg9xKeHFVgGzevzWQ6EQBbw8svPeGEutZvMbLAKCJWrNiHuNkd0nnkGaShNYHooBs5pUh5BChWLoES0AV9r6RQISGUMN4i6h_3P13iw4rIXs7HQ1XjnzEXyyLgBxCKm-NaSUyPVhXUMSvC0YGtQcAvY_DDsDX4i-trDm8PyWmbABdJ9xv61kwW9Fq6KuCgNf8EVObAMJhAVUfcoLvhFt9ia_g==&p=1&fvj=1&vjs=3\n"
     ]
    }
   ],
   "source": [
    "xx = pd.read_csv(\"indeed.csv\")\n",
    "\n",
    "print(xx.iloc[35][\"URL\"])\n",
    "print(xx.iloc[45][\"URL\"])\n",
    "print(xx.iloc[48][\"URL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Titre</th>\n",
       "      <th>Nom entreprise</th>\n",
       "      <th>Adresse</th>\n",
       "      <th>Date de publication</th>\n",
       "      <th>salaire</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Sup3r D√©veloppeur Web Full Stack @Startup</td>\n",
       "      <td>GlobeSailor SAS</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-03 03:11:00.197236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4pp31 4 T0u5 135 D3v310p3r5 w3b full st4k !\\nP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>D√©veloppeur Informatique H/F</td>\n",
       "      <td>VALENTE SECURYSTAR</td>\n",
       "      <td>94320 Thiais</td>\n",
       "      <td>2019-10-02 03:11:14.353355</td>\n",
       "      <td>1¬†850 ‚Ç¨ par mois</td>\n",
       "      <td>VALENTE SECURYSTAR, fabricant de portes blind√©...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>D√©veloppeur Android (H/F)</td>\n",
       "      <td>Universign</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-04 03:11:27.090785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Universign est le pure player de r√©f√©rence sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>D√©veloppeur Ionic / Firebase</td>\n",
       "      <td>NEXTT</td>\n",
       "      <td>92200 Neuilly-sur-Seine</td>\n",
       "      <td>2019-09-19 03:11:39.836685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dans le cadre du d√©veloppement d'une applicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Data Engineer / D√©veloppeur NLP H/F</td>\n",
       "      <td>Wolters Kluwer</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-04 03:11:53.014114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au sein du P√¥le Droit et R√©glementation, ratta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>D√©veloppeur Java H/F</td>\n",
       "      <td>Ratp Smart Systems</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-10 03:12:05.948019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1er jet :\\nPour acc√©l√©rer sa transformation et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=6986aa9ce3ca25...</td>\n",
       "      <td>D√©veloppeur iOS (H/F)</td>\n",
       "      <td>Universign</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-01 03:12:18.742210</td>\n",
       "      <td>-</td>\n",
       "      <td>Universign est le pure player de r√©f√©rence sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=8ee618fc0da425...</td>\n",
       "      <td>BALENCIAGA - Coordinateur/trice D√©veloppement ...</td>\n",
       "      <td>Groupe Kering</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-03 16:12:31.688147</td>\n",
       "      <td>-</td>\n",
       "      <td>Summary\\nFond√©e en 1917 par l‚ÄôEspagnol Crist√≥b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=2f40c0f1d86b7b...</td>\n",
       "      <td>D√©veloppeur Junior (ReactJS / Node.js)</td>\n",
       "      <td>AKOYA</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-01 03:12:44.296664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AKOYA GENIUS\\nEn compl√©ment de ses activit√©s d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=fdb86ccd993a5c...</td>\n",
       "      <td>BALENCIAGA - Coordinateur/trice D√©veloppement ...</td>\n",
       "      <td>Balenciaga</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-03 15:12:57.009145</td>\n",
       "      <td>-</td>\n",
       "      <td>Summary\\nFond√©e en 1917 par l‚ÄôEspagnol Crist√≥b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.indeed.fr/company/LA-HALLE/jobs/D%...</td>\n",
       "      <td>D√©veloppeur Produit / Acheteur (CDI) H/F</td>\n",
       "      <td>LA HALLE</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-17 03:13:09.672707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LA HALLE C‚ÄôEST VRAIMENT VOUS !\\nC‚Äôest beau une...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.indeed.fr/company/Verduron/jobs/D%...</td>\n",
       "      <td>D√©veloppeur Java Junior- H/F</td>\n",
       "      <td>Verduron</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-03 18:13:22.470619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missions du d√©veloppeur Java Junior\\nTravail s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=b1d626dec638c5...</td>\n",
       "      <td>D√©veloppeur informatique (F/H)</td>\n",
       "      <td>Aryzta Food Solutions</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-04 03:13:34.851405</td>\n",
       "      <td>-</td>\n",
       "      <td>Contrat d‚Äôapprentissage/de professionnalisatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=846f7f5da2e3fa...</td>\n",
       "      <td>D√âVELOPPEUR(-EUSE) PRODUIT PAP (F/H) - CDD</td>\n",
       "      <td>Louis Vuitton</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-19 03:13:48.700635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poste\\nLe/la d√©veloppeur(-se) Produit est resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://www.indeed.fr/company/Verduron/jobs/D%...</td>\n",
       "      <td>D√©veloppeur Back-End Node.js H/F</td>\n",
       "      <td>Verduron</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-03 18:14:01.712690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Il s‚Äôagit d‚Äôun poste de d√©veloppeur Back end n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=4a635660dee1b3...</td>\n",
       "      <td>Charg√©.e accueil Tank</td>\n",
       "      <td>Spintank</td>\n",
       "      <td>75011 Paris 11e</td>\n",
       "      <td>2019-09-28 03:14:14.503565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Le Tank\\nCr√©√© en janvier 2015 par l‚Äôagence Spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>D√©veloppeur commercial</td>\n",
       "      <td>Denise omer design</td>\n",
       "      <td>Paris 8e (75)</td>\n",
       "      <td>2019-09-08 03:14:27.184192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dirigeante d‚Äôune agence d‚Äôarchitecture int√©rie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>D√©veloppeur Software 3D / Unity 3D / RM &amp; RA /...</td>\n",
       "      <td>Theoris</td>\n",
       "      <td>75010 Paris 10e</td>\n",
       "      <td>2019-09-04 03:14:40.036136</td>\n",
       "      <td>36¬†000 ‚Ç¨ - 50¬†000 ‚Ç¨ par an</td>\n",
       "      <td>Vous √™tes passionn√© de D√©veloppement Software ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>D√©veloppeur Java H/F</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-18 03:14:52.824910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D√©veloppeur JAVA JEE H/F\\nCapgemini qu‚Äôest-ce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>D√©veloppeur Fullstack</td>\n",
       "      <td>Data Impact</td>\n",
       "      <td>75010 Paris 10e</td>\n",
       "      <td>2019-09-04 03:15:07.805116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DATA IMPACT, C‚ÄôEST QUOI ?\\nLe d√©veloppement tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>D√©veloppeur Software 3D / Unity 3D / RM &amp; RA /...</td>\n",
       "      <td>Theoris</td>\n",
       "      <td>75010 Paris 10e</td>\n",
       "      <td>2019-09-04 03:15:20.729575</td>\n",
       "      <td>36¬†000 ‚Ç¨ - 50¬†000 ‚Ç¨ par an</td>\n",
       "      <td>Vous √™tes passionn√© de D√©veloppement Software ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>D√©veloppeur commercial</td>\n",
       "      <td>Denise omer design</td>\n",
       "      <td>Paris 8e (75)</td>\n",
       "      <td>2019-09-08 03:15:33.381852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dirigeante d‚Äôune agence d‚Äôarchitecture int√©rie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Data Engineer / D√©veloppeur NLP H/F</td>\n",
       "      <td>Wolters Kluwer</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-04 03:15:46.068733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au sein du P√¥le Droit et R√©glementation, ratta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>D√©veloppeur Android (H/F)</td>\n",
       "      <td>Universign</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-04 03:15:58.919100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Universign est le pure player de r√©f√©rence sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>D√©veloppeur Ionic / Firebase</td>\n",
       "      <td>NEXTT</td>\n",
       "      <td>92200 Neuilly-sur-Seine</td>\n",
       "      <td>2019-09-19 03:16:12.678519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dans le cadre du d√©veloppement d'une applicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://www.indeed.fr/company/IDEMAPS/jobs/D%C...</td>\n",
       "      <td>D√©veloppeur informatique H/F</td>\n",
       "      <td>IDEMAPS</td>\n",
       "      <td>Rueil-Malmaison (92)</td>\n",
       "      <td>2019-10-03 18:16:25.839854</td>\n",
       "      <td>25¬†000 ‚Ç¨ - 35¬†000 ‚Ç¨ par an</td>\n",
       "      <td>Informations sur l‚Äôentreprise\\nQualis, Xerolab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://www.indeed.fr/company/Insta/jobs/D%C3%...</td>\n",
       "      <td>D√©veloppeur Junior en alternance (H/F)</td>\n",
       "      <td>INSTA</td>\n",
       "      <td>75005 Paris 5e</td>\n",
       "      <td>2019-09-17 03:16:39.574010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Description du poste\\nL'√©cole INSTA, √©cole sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://www.indeed.fr/company/LEC-Conseil/jobs...</td>\n",
       "      <td>D√©veloppeur Fullstack F/H</td>\n",
       "      <td>Tiime</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-28 03:16:52.694543</td>\n",
       "      <td>-</td>\n",
       "      <td>Qui sommes-nous ?\\nTiime est une start-up de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://www.indeed.fr/company/OCTOPUS-IT/jobs/...</td>\n",
       "      <td>D√©veloppeur Front-end React | Editeur de logic...</td>\n",
       "      <td>OCTOPUS IT</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-03 03:17:05.319803</td>\n",
       "      <td>45¬†000 ‚Ç¨ - 60¬†000 ‚Ç¨ par an</td>\n",
       "      <td>La soci√©t√©\\nCet √©diteur de logiciel de 50 pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https://www.indeed.fr/company/CREATIVE-INGENIE...</td>\n",
       "      <td>D√©veloppeur PHP H/F</td>\n",
       "      <td>CREATIVE INGENIERIE</td>\n",
       "      <td>Paris 6e (75)</td>\n",
       "      <td>2019-09-25 03:17:19.447111</td>\n",
       "      <td>40¬†000 ‚Ç¨ - 55¬†000 ‚Ç¨ par an</td>\n",
       "      <td>LES MISSIONS QUI TE SERONT CONFIEES :\\nDans le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Product Owner H/F</td>\n",
       "      <td>Jellysmack</td>\n",
       "      <td>Levallois-Perret (92)</td>\n",
       "      <td>2019-09-05 03:32:15.070765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr√®s plus de 2 ans de d√©veloppement technique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Software Engineer - Data Science (Paris)</td>\n",
       "      <td>Datadog</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-01 03:32:28.407111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About Datadog:\\nWe're on a mission to build th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Data Scientist (F/H)</td>\n",
       "      <td>Novencia</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-05 03:32:41.541998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contexte\\nData is fuel ! Quelle que soit la fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>Hauts-de-Seine</td>\n",
       "      <td>2019-09-05 03:32:54.535975</td>\n",
       "      <td>-</td>\n",
       "      <td>Odigo\\nOdigo connecte les grandes entreprises ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>INTERN - Data Scientist (m/w/d)</td>\n",
       "      <td>respondi sarl</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-05 03:36:19.169309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>respondi is a company from the online market r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Product Owner H/F</td>\n",
       "      <td>Jellysmack</td>\n",
       "      <td>Levallois-Perret (92)</td>\n",
       "      <td>2019-09-05 03:33:34.823658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr√®s plus de 2 ans de d√©veloppement technique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Software Engineer - Data Science (Paris)</td>\n",
       "      <td>Datadog</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-01 03:33:48.273711</td>\n",
       "      <td>-</td>\n",
       "      <td>About Datadog:\\nWe're on a mission to build th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Data Scientist (F/H)</td>\n",
       "      <td>Novencia</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-05 03:34:01.498359</td>\n",
       "      <td>-</td>\n",
       "      <td>Contexte\\nData is fuel ! Quelle que soit la fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>Hauts-de-Seine</td>\n",
       "      <td>2019-09-05 03:34:14.515548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Odigo\\nOdigo connecte les grandes entreprises ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>INTERN - Data Scientist (m/w/d)</td>\n",
       "      <td>respondi sarl</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-05 03:37:40.847956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>respondi is a company from the online market r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=b9cebaf68e72e6...</td>\n",
       "      <td>Data Scientist ‚Äì Machine Learning ‚Äì Artificial...</td>\n",
       "      <td>One2Team</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-05 03:37:55.340224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Les missions\\nContribuez √† r√©volutionner la ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=7680ec08b8b424...</td>\n",
       "      <td>Data Scientist H/F</td>\n",
       "      <td>Equancy</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-05 03:38:08.069144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equancy recherche un data scientist passionn√© ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=7feab13d2abfed...</td>\n",
       "      <td>Data scientist (H/F) ‚Äì Paris-(H/F)</td>\n",
       "      <td>CREDIT DU NORD</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vos principales missions seront de :\\n\\nManipu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=1d6d6699544f84...</td>\n",
       "      <td>Data Scientist Senior H/F (Paris)</td>\n",
       "      <td>Keyrus</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-04 03:38:35.772487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#DataEnthusiast, mordu d'innovation et explora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>RESPONSABLE DATA SCIENCE ET AI - H/F</td>\n",
       "      <td>BNP Paribas Personal Finance</td>\n",
       "      <td>Levallois-Perret (92)</td>\n",
       "      <td>2019-09-05 03:40:53.960313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RESPONSABLE DATA SCIENCE ET AI - H/F (NUM√âRO D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=630ac7e5876380...</td>\n",
       "      <td>Associate Scientist ‚ÄìMolecular/Cell Biology/Im...</td>\n",
       "      <td>HiFiBiO Therapeutics</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-04 03:38:50.297915</td>\n",
       "      <td>-</td>\n",
       "      <td>HiFiBiO Therapeutics is an emerging multinatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=596a2af6aeb775...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Numberly</td>\n",
       "      <td>75009 Paris 9e</td>\n",
       "      <td>2019-10-02 03:39:03.556458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Job Description\\n\\nNumberly is looking for an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Data Scientist (F/H)</td>\n",
       "      <td>Novencia</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-05 03:36:59.577285</td>\n",
       "      <td>-</td>\n",
       "      <td>Contexte\\nData is fuel ! Quelle que soit la fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=aa7035f857a1e3...</td>\n",
       "      <td>IT Data Scientist</td>\n",
       "      <td>AXAIM Global COO</td>\n",
       "      <td>Puteaux (92)</td>\n",
       "      <td>2019-09-25 03:39:17.049387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Le Data Scientist accompagne les m√©tiers d‚ÄôAXA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>https://www.indeed.fr/rc/clk?jk=6fdb84b4f3ed34...</td>\n",
       "      <td>DATA SCIENTIST F/H</td>\n",
       "      <td>AVISIA</td>\n",
       "      <td>Paris 16e (75)</td>\n",
       "      <td>2019-10-02 03:39:30.006749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L'objectif de nos missions est de faire partic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Software Engineer - Data Science (Paris)</td>\n",
       "      <td>Datadog</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-01 03:39:43.574477</td>\n",
       "      <td>-</td>\n",
       "      <td>About Datadog:\\nWe're on a mission to build th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Product Owner H/F</td>\n",
       "      <td>Jellysmack</td>\n",
       "      <td>Levallois-Perret (92)</td>\n",
       "      <td>2019-09-05 03:39:56.910825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr√®s plus de 2 ans de d√©veloppement technique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Data Scientist (F/H)</td>\n",
       "      <td>Novencia</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-05 03:40:10.590256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contexte\\nData is fuel ! Quelle que soit la fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>https://www.indeed.fr/company/MP-DATA/jobs/Dat...</td>\n",
       "      <td>Data stewart / Data manager</td>\n",
       "      <td>MP DATA</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-04 10:41:07.250783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MP DATA est une soci√©t√© de Conseil sp√©cialis√©e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>https://www.indeed.fr/company/Rocket-4-Sales/j...</td>\n",
       "      <td>Business Developer Data H/F</td>\n",
       "      <td>Rocket 4 Sales - Logiciel SaaS</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-03 03:41:20.484406</td>\n",
       "      <td>60¬†000 ‚Ç¨ - 90¬†000 ‚Ç¨ par an</td>\n",
       "      <td>Rocket4Sales accompagne une entreprise √† taill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Software Engineer - Data Science (Paris)</td>\n",
       "      <td>Datadog</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-10-01 03:41:33.891565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About Datadog:\\nWe're on a mission to build th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Product Owner H/F</td>\n",
       "      <td>Jellysmack</td>\n",
       "      <td>Levallois-Perret (92)</td>\n",
       "      <td>2019-09-05 03:41:47.070333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr√®s plus de 2 ans de d√©veloppement technique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Data Scientist (F/H)</td>\n",
       "      <td>Novencia</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-05 03:42:00.986132</td>\n",
       "      <td>-</td>\n",
       "      <td>Contexte\\nData is fuel ! Quelle que soit la fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>Hauts-de-Seine</td>\n",
       "      <td>2019-09-05 03:42:14.550875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Odigo\\nOdigo connecte les grandes entreprises ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>https://www.indeed.fr/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Administrateur Sales Force (H/F)</td>\n",
       "      <td>OPEN XEROX</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>2019-09-10 03:42:28.129567</td>\n",
       "      <td>2¬†500 ‚Ç¨ - 3¬†000 ‚Ç¨ par mois</td>\n",
       "      <td>Groupe Open Xerox\\nNotre vocation : √™tre le pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1772 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    URL  \\\n",
       "0     https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1     https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "2     https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "3     https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "4     https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "5     https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "6     https://www.indeed.fr/rc/clk?jk=6986aa9ce3ca25...   \n",
       "7     https://www.indeed.fr/rc/clk?jk=8ee618fc0da425...   \n",
       "8     https://www.indeed.fr/rc/clk?jk=2f40c0f1d86b7b...   \n",
       "9     https://www.indeed.fr/rc/clk?jk=fdb86ccd993a5c...   \n",
       "10    https://www.indeed.fr/company/LA-HALLE/jobs/D%...   \n",
       "11    https://www.indeed.fr/company/Verduron/jobs/D%...   \n",
       "12    https://www.indeed.fr/rc/clk?jk=b1d626dec638c5...   \n",
       "13    https://www.indeed.fr/rc/clk?jk=846f7f5da2e3fa...   \n",
       "14    https://www.indeed.fr/company/Verduron/jobs/D%...   \n",
       "15    https://www.indeed.fr/rc/clk?jk=4a635660dee1b3...   \n",
       "16    https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "17    https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "18    https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "19    https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "20    https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "21    https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "22    https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "23    https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "24    https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "25    https://www.indeed.fr/company/IDEMAPS/jobs/D%C...   \n",
       "26    https://www.indeed.fr/company/Insta/jobs/D%C3%...   \n",
       "27    https://www.indeed.fr/company/LEC-Conseil/jobs...   \n",
       "28    https://www.indeed.fr/company/OCTOPUS-IT/jobs/...   \n",
       "29    https://www.indeed.fr/company/CREATIVE-INGENIE...   \n",
       "...                                                 ...   \n",
       "1742  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1743  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1744  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1745  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1746  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1747  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1748  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1749  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1750  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1751  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1752  https://www.indeed.fr/rc/clk?jk=b9cebaf68e72e6...   \n",
       "1753  https://www.indeed.fr/rc/clk?jk=7680ec08b8b424...   \n",
       "1754  https://www.indeed.fr/rc/clk?jk=7feab13d2abfed...   \n",
       "1755  https://www.indeed.fr/rc/clk?jk=1d6d6699544f84...   \n",
       "1756  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1757  https://www.indeed.fr/rc/clk?jk=630ac7e5876380...   \n",
       "1758  https://www.indeed.fr/rc/clk?jk=596a2af6aeb775...   \n",
       "1759  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1760  https://www.indeed.fr/rc/clk?jk=aa7035f857a1e3...   \n",
       "1761  https://www.indeed.fr/rc/clk?jk=6fdb84b4f3ed34...   \n",
       "1762  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1763  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1764  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1765  https://www.indeed.fr/company/MP-DATA/jobs/Dat...   \n",
       "1766  https://www.indeed.fr/company/Rocket-4-Sales/j...   \n",
       "1767  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1768  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1769  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1770  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1771  https://www.indeed.fr/pagead/clk?mo=r&ad=-6NYl...   \n",
       "\n",
       "                                                  Titre  \\\n",
       "0             Sup3r D√©veloppeur Web Full Stack @Startup   \n",
       "1                          D√©veloppeur Informatique H/F   \n",
       "2                             D√©veloppeur Android (H/F)   \n",
       "3                          D√©veloppeur Ionic / Firebase   \n",
       "4                   Data Engineer / D√©veloppeur NLP H/F   \n",
       "5                                  D√©veloppeur Java H/F   \n",
       "6                                 D√©veloppeur iOS (H/F)   \n",
       "7     BALENCIAGA - Coordinateur/trice D√©veloppement ...   \n",
       "8                D√©veloppeur Junior (ReactJS / Node.js)   \n",
       "9     BALENCIAGA - Coordinateur/trice D√©veloppement ...   \n",
       "10             D√©veloppeur Produit / Acheteur (CDI) H/F   \n",
       "11                         D√©veloppeur Java Junior- H/F   \n",
       "12                       D√©veloppeur informatique (F/H)   \n",
       "13           D√âVELOPPEUR(-EUSE) PRODUIT PAP (F/H) - CDD   \n",
       "14                     D√©veloppeur Back-End Node.js H/F   \n",
       "15                               Charg√©.e accueil Tank    \n",
       "16                               D√©veloppeur commercial   \n",
       "17    D√©veloppeur Software 3D / Unity 3D / RM & RA /...   \n",
       "18                                 D√©veloppeur Java H/F   \n",
       "19                                D√©veloppeur Fullstack   \n",
       "20    D√©veloppeur Software 3D / Unity 3D / RM & RA /...   \n",
       "21                               D√©veloppeur commercial   \n",
       "22                  Data Engineer / D√©veloppeur NLP H/F   \n",
       "23                            D√©veloppeur Android (H/F)   \n",
       "24                         D√©veloppeur Ionic / Firebase   \n",
       "25                         D√©veloppeur informatique H/F   \n",
       "26               D√©veloppeur Junior en alternance (H/F)   \n",
       "27                            D√©veloppeur Fullstack F/H   \n",
       "28    D√©veloppeur Front-end React | Editeur de logic...   \n",
       "29                                  D√©veloppeur PHP H/F   \n",
       "...                                                 ...   \n",
       "1742                                  Product Owner H/F   \n",
       "1743           Software Engineer - Data Science (Paris)   \n",
       "1744                               Data Scientist (F/H)   \n",
       "1745                                     Data Scientist   \n",
       "1746                    INTERN - Data Scientist (m/w/d)   \n",
       "1747                                  Product Owner H/F   \n",
       "1748           Software Engineer - Data Science (Paris)   \n",
       "1749                               Data Scientist (F/H)   \n",
       "1750                                     Data Scientist   \n",
       "1751                    INTERN - Data Scientist (m/w/d)   \n",
       "1752  Data Scientist ‚Äì Machine Learning ‚Äì Artificial...   \n",
       "1753                                 Data Scientist H/F   \n",
       "1754                 Data scientist (H/F) ‚Äì Paris-(H/F)   \n",
       "1755                  Data Scientist Senior H/F (Paris)   \n",
       "1756               RESPONSABLE DATA SCIENCE ET AI - H/F   \n",
       "1757  Associate Scientist ‚ÄìMolecular/Cell Biology/Im...   \n",
       "1758                                     Data Scientist   \n",
       "1759                               Data Scientist (F/H)   \n",
       "1760                                  IT Data Scientist   \n",
       "1761                                 DATA SCIENTIST F/H   \n",
       "1762           Software Engineer - Data Science (Paris)   \n",
       "1763                                  Product Owner H/F   \n",
       "1764                               Data Scientist (F/H)   \n",
       "1765                        Data stewart / Data manager   \n",
       "1766                        Business Developer Data H/F   \n",
       "1767           Software Engineer - Data Science (Paris)   \n",
       "1768                                  Product Owner H/F   \n",
       "1769                               Data Scientist (F/H)   \n",
       "1770                                     Data Scientist   \n",
       "1771                   Administrateur Sales Force (H/F)   \n",
       "\n",
       "                      Nom entreprise                  Adresse  \\\n",
       "0                    GlobeSailor SAS               Paris (75)   \n",
       "1                 VALENTE SECURYSTAR             94320 Thiais   \n",
       "2                         Universign               Paris (75)   \n",
       "3                              NEXTT  92200 Neuilly-sur-Seine   \n",
       "4                     Wolters Kluwer               Paris (75)   \n",
       "5                 Ratp Smart Systems               Paris (75)   \n",
       "6                         Universign               Paris (75)   \n",
       "7                      Groupe Kering               Paris (75)   \n",
       "8                              AKOYA               Paris (75)   \n",
       "9                         Balenciaga               Paris (75)   \n",
       "10                          LA HALLE               Paris (75)   \n",
       "11                          Verduron               Paris (75)   \n",
       "12             Aryzta Food Solutions               Paris (75)   \n",
       "13                     Louis Vuitton               Paris (75)   \n",
       "14                          Verduron               Paris (75)   \n",
       "15                          Spintank          75011 Paris 11e   \n",
       "16                Denise omer design            Paris 8e (75)   \n",
       "17                           Theoris          75010 Paris 10e   \n",
       "18                         Capgemini               Paris (75)   \n",
       "19                       Data Impact          75010 Paris 10e   \n",
       "20                           Theoris          75010 Paris 10e   \n",
       "21                Denise omer design            Paris 8e (75)   \n",
       "22                    Wolters Kluwer               Paris (75)   \n",
       "23                        Universign               Paris (75)   \n",
       "24                             NEXTT  92200 Neuilly-sur-Seine   \n",
       "25                           IDEMAPS     Rueil-Malmaison (92)   \n",
       "26                             INSTA           75005 Paris 5e   \n",
       "27                             Tiime               Paris (75)   \n",
       "28                        OCTOPUS IT               Paris (75)   \n",
       "29               CREATIVE INGENIERIE            Paris 6e (75)   \n",
       "...                              ...                      ...   \n",
       "1742                      Jellysmack    Levallois-Perret (92)   \n",
       "1743                         Datadog               Paris (75)   \n",
       "1744                        Novencia               Paris (75)   \n",
       "1745                       Capgemini           Hauts-de-Seine   \n",
       "1746                   respondi sarl               Paris (75)   \n",
       "1747                      Jellysmack    Levallois-Perret (92)   \n",
       "1748                         Datadog               Paris (75)   \n",
       "1749                        Novencia               Paris (75)   \n",
       "1750                       Capgemini           Hauts-de-Seine   \n",
       "1751                   respondi sarl               Paris (75)   \n",
       "1752                        One2Team               Paris (75)   \n",
       "1753                         Equancy               Paris (75)   \n",
       "1754                  CREDIT DU NORD               Paris (75)   \n",
       "1755                          Keyrus               Paris (75)   \n",
       "1756    BNP Paribas Personal Finance    Levallois-Perret (92)   \n",
       "1757            HiFiBiO Therapeutics               Paris (75)   \n",
       "1758                        Numberly           75009 Paris 9e   \n",
       "1759                        Novencia               Paris (75)   \n",
       "1760                AXAIM Global COO             Puteaux (92)   \n",
       "1761                          AVISIA           Paris 16e (75)   \n",
       "1762                         Datadog               Paris (75)   \n",
       "1763                      Jellysmack    Levallois-Perret (92)   \n",
       "1764                        Novencia               Paris (75)   \n",
       "1765                         MP DATA               Paris (75)   \n",
       "1766  Rocket 4 Sales - Logiciel SaaS               Paris (75)   \n",
       "1767                         Datadog               Paris (75)   \n",
       "1768                      Jellysmack    Levallois-Perret (92)   \n",
       "1769                        Novencia               Paris (75)   \n",
       "1770                       Capgemini           Hauts-de-Seine   \n",
       "1771                      OPEN XEROX               Paris (75)   \n",
       "\n",
       "             Date de publication                     salaire  \\\n",
       "0     2019-10-03 03:11:00.197236                         NaN   \n",
       "1     2019-10-02 03:11:14.353355            1¬†850 ‚Ç¨ par mois   \n",
       "2     2019-09-04 03:11:27.090785                         NaN   \n",
       "3     2019-09-19 03:11:39.836685                         NaN   \n",
       "4     2019-09-04 03:11:53.014114                         NaN   \n",
       "5     2019-09-10 03:12:05.948019                         NaN   \n",
       "6     2019-10-01 03:12:18.742210                           -   \n",
       "7     2019-10-03 16:12:31.688147                           -   \n",
       "8     2019-10-01 03:12:44.296664                         NaN   \n",
       "9     2019-10-03 15:12:57.009145                           -   \n",
       "10    2019-09-17 03:13:09.672707                         NaN   \n",
       "11    2019-10-03 18:13:22.470619                         NaN   \n",
       "12    2019-09-04 03:13:34.851405                           -   \n",
       "13    2019-09-19 03:13:48.700635                         NaN   \n",
       "14    2019-10-03 18:14:01.712690                         NaN   \n",
       "15    2019-09-28 03:14:14.503565                         NaN   \n",
       "16    2019-09-08 03:14:27.184192                         NaN   \n",
       "17    2019-09-04 03:14:40.036136  36¬†000 ‚Ç¨ - 50¬†000 ‚Ç¨ par an   \n",
       "18    2019-09-18 03:14:52.824910                         NaN   \n",
       "19    2019-09-04 03:15:07.805116                         NaN   \n",
       "20    2019-09-04 03:15:20.729575  36¬†000 ‚Ç¨ - 50¬†000 ‚Ç¨ par an   \n",
       "21    2019-09-08 03:15:33.381852                         NaN   \n",
       "22    2019-09-04 03:15:46.068733                         NaN   \n",
       "23    2019-09-04 03:15:58.919100                         NaN   \n",
       "24    2019-09-19 03:16:12.678519                         NaN   \n",
       "25    2019-10-03 18:16:25.839854  25¬†000 ‚Ç¨ - 35¬†000 ‚Ç¨ par an   \n",
       "26    2019-09-17 03:16:39.574010                         NaN   \n",
       "27    2019-09-28 03:16:52.694543                           -   \n",
       "28    2019-10-03 03:17:05.319803  45¬†000 ‚Ç¨ - 60¬†000 ‚Ç¨ par an   \n",
       "29    2019-09-25 03:17:19.447111  40¬†000 ‚Ç¨ - 55¬†000 ‚Ç¨ par an   \n",
       "...                          ...                         ...   \n",
       "1742  2019-09-05 03:32:15.070765                         NaN   \n",
       "1743  2019-10-01 03:32:28.407111                         NaN   \n",
       "1744  2019-09-05 03:32:41.541998                         NaN   \n",
       "1745  2019-09-05 03:32:54.535975                           -   \n",
       "1746  2019-09-05 03:36:19.169309                         NaN   \n",
       "1747  2019-09-05 03:33:34.823658                         NaN   \n",
       "1748  2019-10-01 03:33:48.273711                           -   \n",
       "1749  2019-09-05 03:34:01.498359                           -   \n",
       "1750  2019-09-05 03:34:14.515548                         NaN   \n",
       "1751  2019-09-05 03:37:40.847956                         NaN   \n",
       "1752  2019-09-05 03:37:55.340224                         NaN   \n",
       "1753  2019-09-05 03:38:08.069144                         NaN   \n",
       "1754                         NaN                         NaN   \n",
       "1755  2019-10-04 03:38:35.772487                         NaN   \n",
       "1756  2019-09-05 03:40:53.960313                         NaN   \n",
       "1757  2019-10-04 03:38:50.297915                           -   \n",
       "1758  2019-10-02 03:39:03.556458                         NaN   \n",
       "1759  2019-09-05 03:36:59.577285                           -   \n",
       "1760  2019-09-25 03:39:17.049387                         NaN   \n",
       "1761  2019-10-02 03:39:30.006749                         NaN   \n",
       "1762  2019-10-01 03:39:43.574477                           -   \n",
       "1763  2019-09-05 03:39:56.910825                         NaN   \n",
       "1764  2019-09-05 03:40:10.590256                         NaN   \n",
       "1765  2019-10-04 10:41:07.250783                         NaN   \n",
       "1766  2019-10-03 03:41:20.484406  60¬†000 ‚Ç¨ - 90¬†000 ‚Ç¨ par an   \n",
       "1767  2019-10-01 03:41:33.891565                         NaN   \n",
       "1768  2019-09-05 03:41:47.070333                         NaN   \n",
       "1769  2019-09-05 03:42:00.986132                           -   \n",
       "1770  2019-09-05 03:42:14.550875                         NaN   \n",
       "1771  2019-09-10 03:42:28.129567  2¬†500 ‚Ç¨ - 3¬†000 ‚Ç¨ par mois   \n",
       "\n",
       "                                            description  \n",
       "0     4pp31 4 T0u5 135 D3v310p3r5 w3b full st4k !\\nP...  \n",
       "1     VALENTE SECURYSTAR, fabricant de portes blind√©...  \n",
       "2     Universign est le pure player de r√©f√©rence sur...  \n",
       "3     Dans le cadre du d√©veloppement d'une applicati...  \n",
       "4     Au sein du P√¥le Droit et R√©glementation, ratta...  \n",
       "5     1er jet :\\nPour acc√©l√©rer sa transformation et...  \n",
       "6     Universign est le pure player de r√©f√©rence sur...  \n",
       "7     Summary\\nFond√©e en 1917 par l‚ÄôEspagnol Crist√≥b...  \n",
       "8     AKOYA GENIUS\\nEn compl√©ment de ses activit√©s d...  \n",
       "9     Summary\\nFond√©e en 1917 par l‚ÄôEspagnol Crist√≥b...  \n",
       "10    LA HALLE C‚ÄôEST VRAIMENT VOUS !\\nC‚Äôest beau une...  \n",
       "11    Missions du d√©veloppeur Java Junior\\nTravail s...  \n",
       "12    Contrat d‚Äôapprentissage/de professionnalisatio...  \n",
       "13    Poste\\nLe/la d√©veloppeur(-se) Produit est resp...  \n",
       "14    Il s‚Äôagit d‚Äôun poste de d√©veloppeur Back end n...  \n",
       "15    Le Tank\\nCr√©√© en janvier 2015 par l‚Äôagence Spi...  \n",
       "16    Dirigeante d‚Äôune agence d‚Äôarchitecture int√©rie...  \n",
       "17    Vous √™tes passionn√© de D√©veloppement Software ...  \n",
       "18    D√©veloppeur JAVA JEE H/F\\nCapgemini qu‚Äôest-ce ...  \n",
       "19    DATA IMPACT, C‚ÄôEST QUOI ?\\nLe d√©veloppement tr...  \n",
       "20    Vous √™tes passionn√© de D√©veloppement Software ...  \n",
       "21    Dirigeante d‚Äôune agence d‚Äôarchitecture int√©rie...  \n",
       "22    Au sein du P√¥le Droit et R√©glementation, ratta...  \n",
       "23    Universign est le pure player de r√©f√©rence sur...  \n",
       "24    Dans le cadre du d√©veloppement d'une applicati...  \n",
       "25    Informations sur l‚Äôentreprise\\nQualis, Xerolab...  \n",
       "26    Description du poste\\nL'√©cole INSTA, √©cole sup...  \n",
       "27    Qui sommes-nous ?\\nTiime est une start-up de l...  \n",
       "28    La soci√©t√©\\nCet √©diteur de logiciel de 50 pers...  \n",
       "29    LES MISSIONS QUI TE SERONT CONFIEES :\\nDans le...  \n",
       "...                                                 ...  \n",
       "1742  Apr√®s plus de 2 ans de d√©veloppement technique...  \n",
       "1743  About Datadog:\\nWe're on a mission to build th...  \n",
       "1744  Contexte\\nData is fuel ! Quelle que soit la fa...  \n",
       "1745  Odigo\\nOdigo connecte les grandes entreprises ...  \n",
       "1746  respondi is a company from the online market r...  \n",
       "1747  Apr√®s plus de 2 ans de d√©veloppement technique...  \n",
       "1748  About Datadog:\\nWe're on a mission to build th...  \n",
       "1749  Contexte\\nData is fuel ! Quelle que soit la fa...  \n",
       "1750  Odigo\\nOdigo connecte les grandes entreprises ...  \n",
       "1751  respondi is a company from the online market r...  \n",
       "1752  Les missions\\nContribuez √† r√©volutionner la ge...  \n",
       "1753  Equancy recherche un data scientist passionn√© ...  \n",
       "1754  Vos principales missions seront de :\\n\\nManipu...  \n",
       "1755  #DataEnthusiast, mordu d'innovation et explora...  \n",
       "1756  RESPONSABLE DATA SCIENCE ET AI - H/F (NUM√âRO D...  \n",
       "1757  HiFiBiO Therapeutics is an emerging multinatio...  \n",
       "1758  Job Description\\n\\nNumberly is looking for an ...  \n",
       "1759  Contexte\\nData is fuel ! Quelle que soit la fa...  \n",
       "1760  Le Data Scientist accompagne les m√©tiers d‚ÄôAXA...  \n",
       "1761  L'objectif de nos missions est de faire partic...  \n",
       "1762  About Datadog:\\nWe're on a mission to build th...  \n",
       "1763  Apr√®s plus de 2 ans de d√©veloppement technique...  \n",
       "1764  Contexte\\nData is fuel ! Quelle que soit la fa...  \n",
       "1765  MP DATA est une soci√©t√© de Conseil sp√©cialis√©e...  \n",
       "1766  Rocket4Sales accompagne une entreprise √† taill...  \n",
       "1767  About Datadog:\\nWe're on a mission to build th...  \n",
       "1768  Apr√®s plus de 2 ans de d√©veloppement technique...  \n",
       "1769  Contexte\\nData is fuel ! Quelle que soit la fa...  \n",
       "1770  Odigo\\nOdigo connecte les grandes entreprises ...  \n",
       "1771  Groupe Open Xerox\\nNotre vocation : √™tre le pa...  \n",
       "\n",
       "[1772 rows x 7 columns]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
