{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndeedItemParser:\n",
    "    def __init__(self):\n",
    "        self.driverPath = \"C:\\\\Users\\\\Junior\\\\Documents\\\\selenium\\\\driver\\\\chromedriver.exe\"\n",
    "        #self.utilities = utilities();\n",
    "        \n",
    "    def _get_title(self, driver):\n",
    "        try:\n",
    "            title = driver.find_element_by_xpath(\"//*[@class='jobsearch-DesktopStickyContainer']//h3\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return title.text\n",
    "    \n",
    "    def _get_name(self, driver):\n",
    "        \n",
    "        try:    \n",
    "            name = driver.find_element_by_xpath(\"//*[contains(@class,'jobsearch-InlineCompanyRating')]//div[1]\")\n",
    "            return name.text\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "    \n",
    "    def _get_address(self,driver):\n",
    "         try:   \n",
    "            address = driver.find_element_by_xpath(\"//*[contains(@class,'jobsearch-InlineCompanyRating')]//div[3]\")\n",
    "            if address.text == \"-\":\n",
    "                address = driver.find_element_by_xpath(\"//*[contains(@class,'jobsearch-InlineCompanyRating')]//div[4]\")\n",
    "            return address.text\n",
    "         except Exception as e:\n",
    "            address = driver.find_element_by_xpath(\"//span[@class='jobsearch-JobMetadataHeader-iconLabel'][1]\")\n",
    "            return address.text\n",
    "    \n",
    "    def _get_salaire(self,driver, description):\n",
    "        return np.nan # à compléter dans la partie pre-processing\n",
    "            \n",
    "    \n",
    "    def _get_description(self,driver):\n",
    "        try:\n",
    "            #jobDescriptionText\n",
    "            e_description = driver.find_element_by_id(\"jobDescriptionText\")\n",
    "            return e_description.text\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    def _get_date(self,driver,url,name):\n",
    "       # print(url)\n",
    "        try:\n",
    "            date_str = driver.find_element_by_xpath(\"//*[@class='jobsearch-JobMetadataFooter']\")\n",
    "            date_str_full = date_str.text\n",
    "            date_tbl = date_str_full.split(\" \")\n",
    "            count_str = date_tbl[4]\n",
    "            label = date_tbl[5]\n",
    "            \n",
    "            if name in date_str_full:\n",
    "                date_str_full = date_str_full.replace(name, \"\")\n",
    "                date_tbl = date_str_full.split(\" \")\n",
    "                count_str = date_tbl[5]\n",
    "                label = date_tbl[6]\n",
    "                \n",
    "            if count_str == \"a\" :\n",
    "                count_str = date_tbl[5]\n",
    "                label = date_tbl[6]\n",
    "                \n",
    "            #print(\"date_str\", date_tbl)\n",
    "            date = datetime.now()\n",
    "            \n",
    "            if count_str == \"30+\":\n",
    "                return date - timedelta(days=30)\n",
    "            \n",
    "            count = int(count_str)\n",
    "            if \"jour\" in label:\n",
    "                date = date - timedelta(days=count)\n",
    "            elif \"heur\" in label:\n",
    "                date = date - timedelta(hours=count)\n",
    "            return date;\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    \n",
    "    def parse(self,url):\n",
    "        driver = webdriver.Chrome(self.driverPath)\n",
    "        driver.get(url)\n",
    "        driver.maximize_window()\n",
    "        \n",
    "        source = driver.page_source\n",
    "        title = self._get_title(driver)\n",
    "        name = self._get_name(driver)\n",
    "        address = self._get_address(driver)\n",
    "        date = self._get_date(driver, url,name)\n",
    "        description = self._get_description(driver)\n",
    "        salaire = self._get_salaire(driver,description)\n",
    "        \n",
    "        driver.quit()\n",
    "        \n",
    "        return title, name, address, date, salaire, description, source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyWordsProvider:\n",
    "    \n",
    "    def get_langages(self):\n",
    "        return ['python', 'r','vba', 'mysql','excel','asp.net','nosql','sql','linux','mongodb',\n",
    "            'mariadb','java','javascript','php','html','css','sas','c#','ruby','swift','objective-c',\n",
    "            'vb.net','kotlin','scala','bash','powershell','shell','front end','back end','soap']\n",
    "    \n",
    "    def get_tools(self):\n",
    "        return ['tableau', 'powerbi','symfony', 'jquery','angular','react','react native','node js','git','github',\n",
    "            'visual studio','django','flask','api rest','laravel', 'hololens', 'docker', 'jira', 'scrum', 'kanban', \n",
    "               'azure','aws', 'teamcity', 'jenkins']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os.path\n",
    "import os\n",
    "class IndeedPaser:\n",
    "    def __init__(self):\n",
    "        self.website = \"https://www.indeed.fr\"\n",
    "        self.driverPath = \"C:\\\\Users\\\\Junior\\\\Documents\\\\selenium\\\\driver\\\\chromedriver.exe\"\n",
    "        \n",
    "        self.dataset = pd.read_csv(\"indeed.csv\")\n",
    "        \n",
    "        self.jobs = [\"développeur\", \"data scientist\", \"data analyst\", \"business intelligence\"]\n",
    "        self.locations = [\"Paris\",\"Lyon\", \"Toulouse\", \"Nantes\", \"Bordeaux\"]\n",
    "        #self.utilities =  utilities()\n",
    "        self.indeed_item_parser = IndeedItemParser()\n",
    "        self.parser_state = IndeedParserStateHandler()\n",
    "        self.keyWordsProvider = KeyWordsProvider()\n",
    "    \n",
    "    def _get_pages_counts(self,driver):\n",
    "        searchCountPages_elt = driver.find_element_by_id(\"searchCountPages\")\n",
    "        searchCountPages = searchCountPages_elt.text.split()\n",
    "        if len(searchCountPages) == 6:\n",
    "            searchCountPages = int(\"{0}{1}\".format(searchCountPages[3],searchCountPages[4])) \n",
    "        else :\n",
    "            searchCountPages = searchCountPages[3]  \n",
    "        \n",
    "        return (int(searchCountPages) // 18)\n",
    "    \n",
    "    def _get_subs_collections(self,items, nbr=5):\n",
    "        result = []\n",
    "        sub = []\n",
    "        for index, item in enumerate(items):\n",
    "            sub.append(item)\n",
    "            if (index > 0) & (index % nbr) == 0:\n",
    "                result.append(sub)\n",
    "                sub = []\n",
    "        return result\n",
    "    \n",
    "    def _local_parse_page(self, item_link, localtion, index_i, dataset_len):\n",
    "        try:\n",
    "            if (self.dataset[\"URL\"].isin([item_link]).any()):\n",
    "                print(\"aready parsed, skip\", item_link)\n",
    "            else:\n",
    "                title, name, address, date,salaire, description, source = self.indeed_item_parser.parse(item_link)\n",
    "                if (self.dataset[\"Titre\"].isin([title]).any() \n",
    "                    & self.dataset[\"Nom entreprise\"].isin([name]).any() \n",
    "                    & self.dataset[\"Adresse\"].isin([address]).any()\n",
    "                    & self.dataset[\"description\"].isin([description]).any()):\n",
    "                    print(\"doublon, skip.\")\n",
    "                    return\n",
    "                \n",
    "                cols = [item_link, title, name, address, date, salaire, description,localtion ]\n",
    "                self.dataset.loc[dataset_len + index_i] = cols\n",
    "                source_file_name = \"source_file.{0}.html\".format(dataset_len + index_i)\n",
    "                if not os.path.exists(source_file_name):\n",
    "                    file = open(\"pages/{0}\".format(source_file_name), \"w\")\n",
    "                    source = item_link + \"----------------\" + source\n",
    "                    file.write(source)\n",
    "                    file.close()\n",
    "                print(\"len(dataset)\", len(self.dataset))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    \n",
    "    def parse(self):\n",
    "        browser = webdriver.Chrome(self.driverPath)\n",
    "        browser.get(self.website)\n",
    "        browser.maximize_window()\n",
    "        \n",
    "        for job in self.jobs:\n",
    "            jobs_filter_list = [job]\n",
    "            \n",
    "            if job == \"développeur\":\n",
    "                all_competences = self.keyWordsProvider.get_langages() + self.keyWordsProvider.get_tools()\n",
    "                jobs_filter_list = [\"{0} {1}\".format(job, item) for item in all_competences]\n",
    "            \n",
    "            for job_key_word in jobs_filter_list:\n",
    "                for location in self.locations:\n",
    "\n",
    "                    query = \"https://www.indeed.fr/jobs?q={0}&l={1}\".format(job_key_word, location)\n",
    "                    browser.get(query)\n",
    "\n",
    "                    pages_count = self._get_pages_counts(browser)\n",
    "\n",
    "                    for page_index in range(1, pages_count):\n",
    "                        full_query = \"{0}&start={1}\".format(query,page_index)\n",
    "\n",
    "                        browser.get(full_query)\n",
    "\n",
    "                        items = browser.find_elements_by_xpath(\"//*[contains(@class,'clickcard')]//*[contains(@class,'jobtitle')]\")\n",
    "                        items = [item.get_attribute(\"href\") for item in  items]\n",
    "                        dataset_len = len(self.dataset)\n",
    "                        \n",
    "                        #collections = self._get_subs_collections(items)\n",
    "                        for index_i, link in enumerate(items):\n",
    "                            self._local_parse_page(link, location, index_i,dataset_len)\n",
    "                        \n",
    "                        self.dataset.to_csv(\"indeed.csv\",index=False)\n",
    "                        #print(\"indeed.csv saved\")\n",
    "                        self.dataset = pd.read_csv(\"indeed.csv\")\n",
    "                \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doublon, skip.\n",
      "doublon, skip.\n",
      "len(dataset) 20\n",
      "doublon, skip.\n",
      "doublon, skip.\n",
      "len(dataset) 21\n",
      "aready parsed, skip https://www.indeed.fr/rc/clk?jk=7de11d138b3a2b85&fccid=0bc9d524dbf6f889&vjs=3\n",
      "aready parsed, skip https://www.indeed.fr/company/Flowka/jobs/D%C3%A9veloppeur-Fullstack-Junior-0f4aa189d14603a5?fccid=0a8ff107c11b8f22&vjs=3\n",
      "aready parsed, skip https://www.indeed.fr/rc/clk?jk=96c9eb4c4a5cca53&fccid=1c939006b684b25c&vjs=3\n",
      "aready parsed, skip https://www.indeed.fr/company/LEC-Conseil/jobs/D%C3%A9veloppeur-Fullstack-F-H-f5b68ff17d9cd4f4?fccid=3d3e7ac112fae637&vjs=3\n",
      "len(dataset) 22\n",
      "aready parsed, skip https://www.indeed.fr/company/OCTOPUS-IT/jobs/D%C3%A9veloppeur-Python-Junior-Dipl%C3%B4m%C3%A9-Logiciel-Open-Source-c40fbad4cbf04651?fccid=7358eb8948faec3a&vjs=3\n",
      "aready parsed, skip https://www.indeed.fr/company/Data-Impact-Analytics/jobs/D%C3%A9veloppeur-Python-Junior-1a815b2313a4f6fc?fccid=f117fa20a31c19b8&vjs=3\n",
      "len(dataset) 23\n",
      "len(dataset) 24\n",
      "len(dataset) 25\n",
      "doublon, skip.\n",
      "doublon, skip.\n",
      "doublon, skip.\n",
      "len(dataset) 26\n",
      "aready parsed, skip https://www.indeed.fr/company/Flowka/jobs/D%C3%A9veloppeur-Fullstack-Junior-0f4aa189d14603a5?fccid=0a8ff107c11b8f22&vjs=3\n",
      "aready parsed, skip https://www.indeed.fr/rc/clk?jk=96c9eb4c4a5cca53&fccid=1c939006b684b25c&vjs=3\n",
      "aready parsed, skip https://www.indeed.fr/company/Verduron/jobs/D%C3%A9veloppeur-Python-Golang-b2fdce19906b1e11?fccid=0d02f1f8135a708a&vjs=3\n",
      "aready parsed, skip https://www.indeed.fr/company/LEC-Conseil/jobs/D%C3%A9veloppeur-Fullstack-F-H-f5b68ff17d9cd4f4?fccid=3d3e7ac112fae637&vjs=3\n",
      "aready parsed, skip https://www.indeed.fr/rc/clk?jk=304bffed0ad411e3&fccid=9b6c70e895ae496c&vjs=3\n",
      "aready parsed, skip https://www.indeed.fr/company/OCTOPUS-IT/jobs/D%C3%A9veloppeur-Python-Junior-Dipl%C3%B4m%C3%A9-Logiciel-Open-Source-c40fbad4cbf04651?fccid=7358eb8948faec3a&vjs=3\n",
      "aready parsed, skip https://www.indeed.fr/company/Data-Impact-Analytics/jobs/D%C3%A9veloppeur-Python-Junior-1a815b2313a4f6fc?fccid=f117fa20a31c19b8&vjs=3\n",
      "len(dataset) 27\n",
      "aready parsed, skip https://www.indeed.fr/company/CACIIS/jobs/D%C3%A9veloppeur-Python-3c4ee40bef6c511b?fccid=f70036a8c6ec7866&vjs=3\n",
      "aready parsed, skip https://www.indeed.fr/rc/clk?jk=ae44d9df5b25af01&fccid=0e58d71eecbefc83&vjs=3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-95d8a4475e97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIndeedPaser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-8f319a929218>\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m                         \u001b[1;31m#collections = self._get_subs_collections(items)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mindex_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_local_parse_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"indeed.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-8f319a929218>\u001b[0m in \u001b[0;36m_local_parse_page\u001b[1;34m(self, item_link, localtion, index_i, dataset_len)\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"aready parsed, skip\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msalaire\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindeed_item_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                 if (self.dataset[\"Titre\"].isin([title]).any() \n\u001b[0;32m     45\u001b[0m                     \u001b[1;33m&\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Nom entreprise\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-f0a5c79c0cb1>\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriverPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     70\u001b[0m             return self.request_encode_body(method, url, fields=fields,\n\u001b[0;32m     71\u001b[0m                                             \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                                             **urlopen_kw)\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     def request_encode_url(self, method, url, fields=None, headers=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = IndeedPaser()\n",
    "test.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "class IndedRegexParser:\n",
    "    \n",
    "    def __init__(self, descriptif_text ):\n",
    "        self.descriptif_text = descriptif_text\n",
    "    \n",
    "    def _get_items(self,pattern):   \n",
    "        result_re = re.findall(pattern,self.descriptif_text)\n",
    "        result = []\n",
    "        for item_l_1 in result_re:\n",
    "            for item_l_2 in item_l_1:\n",
    "                if item_l_2 != \"\":\n",
    "                    result.append(item_l_2)\n",
    "        return result\n",
    "    \n",
    "    def _get_niveau_experience(self):\n",
    "        #Niveau d'expérience : regex true\n",
    "        result = self._get_items('([(e|E)\\w+]xpérience?:?\\s\\d{1,15} ans?)|([(e|E)\\w+]xpérience?\\s?de\\s?\\d{1,15} ans?)|(\\d{1,15} ans d\\'[e|E]xpérience[s]?)')\n",
    "        if len(result) == 0:\n",
    "            outer = re.compile(r'Expérience:\\s*.+:( (\\w) (an|ans) \\(((R|r)equis|(s|S)ouhaité)\\))')\n",
    "            m = outer.search(self.descriptif_text)\n",
    "            if m is not None:\n",
    "                return m.group(1)\n",
    "            #return []\n",
    "    \n",
    "    def _get_salaires(self):\n",
    "        #Salaire ajusté en fonction du coût de la vie dans les différentes villes : regex true\n",
    "        #return self._get_items('(\\d{2,3}\\s?(k|K)?)|(\\d{2,3}\\s?\\d{3,5}\\s?(k|K)?)|([(s|S)]alaire?[\\s]?:?[\\s]?\\d{2,6}k?)|([(r|R)]émunération?[\\s]?:?[\\s]?\\d{2,6}k?)|([(g|G)]ratification?[\\s]?:?[\\s]?\\d{2,6}k?)') \n",
    "        #[[S|s]alaire?[\\s+]?:?[\\s+]?(.*)e?[\\s+]?\\/an\n",
    "        outer = re.compile(r'[[S|s]alaire?[\\s+]?:?[\\s+]?(.*)e?[\\s+]?\\/(an|mois)|(.*)?[\\s+]?par?[\\s+]?mois')\n",
    "        m = outer.search(self.descriptif_text)\n",
    "        if m is not None:\n",
    "            return m.group(1)\n",
    "        return []\n",
    "            \n",
    "        \n",
    "    \n",
    "    def get_langages_prog(self):\n",
    "        #Langages de programmation requis (R, Python, Excel (VBA), SQL, C++, Java, SAS...): regex true\n",
    "        return self._get_items('(R+[^\\w])|([(p|P)\\w+]ython?)|(Excel?)|(VBA?)|(C\\+\\+?)||(C?)|(Asp.net?)|(SQL?)|(NoSQL?)|(Linux?)|(MySQL?)|(MongoDB?)|(DBMaria?)|(SQL Server?)||(Java?)|(JavaScript?)|(PHP?\\s?\\d{1,}?)|(HTML?\\s?\\d{1,}?)|(CSS?\\s?\\d{1,}?)|(SAS?)|(C#?)|(Ruby?)|(Swift?)|(Objective-C?)|(VB.NET?)|(Kotlin?)|(Scala?)|(Bash?)|(PowerShell?)|(Shell?)|(Front End?)|(Back End?)')\n",
    "    \n",
    "    def get_outils_re(self):\n",
    "        #Outils requis (Tableau, PowerBI...) : regex true\n",
    "        return self._get_items('([(t|T)\\w+]ableau?)|([(p|P)\\w+]ower[(b|B)\\w+][(i|I)\\w+]?)|([(s|S)\\w+]ymfony?\\s?\\d{1,}?)|([(j|J)\\w+][(q|Q)\\w+]uery?\\s?\\d{1,}?)|([(a|A)\\w+]ngular?[\\s?\\d{1,}]?)|([(r|R)\\w+]eact [(j|J)\\w+][(s|S)\\w+]?)|(React Native?)|(Node JS?)|([(g|G)\\w+]it?)|(Visual Studio?)|(Visual Studio Code?)|(Django?)|(Flask?)|(API REST?)|(http?s?)|(HTTP?S?)')\n",
    "        \n",
    "        \n",
    "    def get_niv_etudes_re(self):\n",
    "        #Niveau d'études requis : regex true\n",
    "        return self._get_items('([(f|F)\\w+]ormation?\\s?[(b|B)\\w+]ac\\s\\+\\s[1-8])|([(b|B)\\w+]ac\\s\\+\\s[1-8])')\n",
    "        \n",
    "    def get_type_cursus_re(self):\n",
    "        #Type de cursus (école ingénieur, master, autodidacte...) : regex true\n",
    "        return self._get_items('([(é|E)\\w+]cole [(i|I)\\w+]ngénieur?)|([(m|M)\\w+]aster?\\s?\\w{3,25})|([(a|A)\\w+]utodidacte?)|([(g|G)\\w+]rande[s]? [(é|E)\\w+]cole[s]?)|([(é|E)\\w+]cole[s]? de [(c|C)\\w+]ommerce[s]?)|([(i|I)\\w+]ngénieur [(i|I)\\w+]nformatique?)')\n",
    "        \n",
    "    def get_type_contrat_re(self):\n",
    "        #Type de contrat : regex true\n",
    "        return self._get_items('[(c|C)\\w+]ontrat?:?\\s\\w{3,25}')\n",
    "    \n",
    "    def get_categorie_developpeur_re(self):\n",
    "        #Grande catégorie : développeur (developeur web, dev mobile,dev) / data regex true\n",
    "        return self._get_items('([(d|D)\\w+]éveloppeu[(r|s)]e? [(f|F)\\w+]ull? [(s|S)\\w+]tack)|([(d|D)\\w+]éveloppeu[(r|s)]e? [(f|F)\\w+]ront[(\\s|\\-)][(e|E)\\w+]nd?)|(développeu[(r|s)]e? Back[(\\s|\\-)][(e|E)\\w+]nd?)|([(d|D)\\w+]éveloppeu[(r|s)]e? [(m|M)\\w+]obile?)|([(d|D)\\w+]éveloppeu[(r|s)]e? [(l|L)\\w+]ogiciel?)|([(s|S)\\w+]oftware [(i|I)\\w+]ngenieer?)|([(d|D)\\w+]éveloppeu[(r|s)]e? [(l|L)\\w+]ogiciels?)|([(d|D)\\w+]éveloppeu[(r|s)]e? [(C|c)\\w+]\\+\\+?)|([(d|D)\\w+]éveloppeu[(r|s)]e? [(c|C)\\w+]#?)|([(d|D)\\w+]éveloppeu[(r|s)]e? [(j|J)\\w+]ava?)')\n",
    "    \n",
    "    def get_categorie_data_re(self):\n",
    "        #Grande catégorie : data regex true\n",
    "        return self._get_items('([(d|D)\\w+]ata [(a|A)\\w+]nalyst?)|([(d|D)\\w+]ata [(s|S)\\w+]cientist?)|([(i|I)\\w+]ngénieu[(r|s)]e? [(m|M)\\w+]achine [(i|I)\\w+]earning?)|([(c|C)\\w+]onsultant [(b|B)\\w+]usiness [(i|I)\\w+]ntelligence)|([(c|C)\\w+]onsultant [(d|D)\\w+]ata)|([(c|C)\\w+]onsultant [(b|B)\\w+]ig [(d|D)\\w+]ata)|([(c|C)\\w+]onsultant BI)')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"indeed.csv\")\n",
    "dataset\n",
    "#print(len(dataset))\n",
    "#for index, row in dataset.iterrows():\n",
    "    #print(row[\"URL\"])\n",
    "    #indedRegexParser = IndedRegexParser(row[\"description\"])\n",
    "    #print(indedRegexParser._get_niveau_experience())\n",
    "    #print(indedRegexParser._get_salaires())\n",
    "    #print(indedRegexParser.get_outils_re())\n",
    "    #print(indedRegexParser.get_niv_etudes_re())\n",
    "    #print(indedRegexParser.get_type_cursus_re())\n",
    "    #print(indedRegexParser.get_type_contrat_re())\n",
    "    #print(indedRegexParser.get_categorie_developpeur_re())\n",
    "    #print(indedRegexParser.get_categorie_data_re())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"indeed.csv\")\n",
    "type(dataset[\"salaire\"][18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from orderedset import OrderedSet\n",
    "from bs4 import BeautifulSoup\n",
    "class LocalIndeedPaser:\n",
    "    def __init__(self):\n",
    "        self.pages_path = r'C:\\Users\\Junior\\Documents\\Projects_Simplon\\Projet_ML_gr3-master\\scrapping\\pages'\n",
    "        self.dataset = pd.read_csv(\"indeed.csv\")\n",
    "        self.salary_pattern = \"[[S|s]alaire?[\\s+]?:?[\\s+]?(.*)e?[\\s+]?\\/(an|mois)|((.*)?[\\s+]?par?[\\s+]?(an|ans|mois|jour|heure))\"\n",
    "        self.keyWordsProvider = KeyWordsProvider()\n",
    "    \n",
    "    def _get_salary(self,select_result):\n",
    "        salary = \"\"\n",
    "        for item in select_result:\n",
    "            if \"€\" in item.text:\n",
    "                outer_salary = re.compile(self.salary_pattern)\n",
    "                m_salary = outer_salary.search(item.text)\n",
    "                if m_salary is not None:\n",
    "                    salary = m_salary.group(0)\n",
    "                    break\n",
    "        return salary\n",
    "    \n",
    "    def save_file(self):\n",
    "        self.dataset.to_csv(\"indeed.csv\",index=False)\n",
    "    \n",
    "    def _get_binnary_list_data(self, input_list):\n",
    "        data = []\n",
    "        for i in range(len(self.dataset)):\n",
    "            inside_data = []\n",
    "            for ele in input_list:\n",
    "                pattern = re.compile(r\"[\\s/\\(\\),]\"+ele+r\"[\\s/\\(\\),]\")\n",
    "                value = pattern.search(self.dataset['description'][i].lower().replace('\\n',' ').replace('\\r',' '))\n",
    "                if value:\n",
    "                    inside_data.append(1)\n",
    "                else:\n",
    "                    inside_data.append(0)\n",
    "            data.append(inside_data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def _set_quantitative_features(self, pattern, col_indice,label_col,func_callback = None):\n",
    "        result = []\n",
    "        for index, row in self.dataset.iterrows():\n",
    "            re_pattern = re.compile(pattern)\n",
    "            value = re_pattern.search(row['description'].lower().replace('\\n',' ').replace('\\r',' '))\n",
    "            if value:\n",
    "                if func_callback is not None:\n",
    "                    result.append(func_callback(value.group(0)))\n",
    "                else:\n",
    "                    result.append(value.group(0))\n",
    "            else:\n",
    "                result.append(None)\n",
    "        \n",
    "        if (label_col not in self.dataset.columns):\n",
    "            self.dataset.insert(col_indice, label_col,result,True)\n",
    "        else:\n",
    "            self.dataset[label_col] = pd.DataFrame(result)\n",
    "        \n",
    "        dummies = self.dataset[label_col].str.get_dummies() \n",
    "        \n",
    "        self._fusion_with_dataset(dummies)\n",
    "        \n",
    "    \n",
    "    def parse_education_level(self):\n",
    "        reg_pattern = \"([(b|B)\\w+]ac\\s*\\+\\s*[1-8])|ingénieur|master\\s*(1|2)|(D|d)iplôme\\s*supérieur\"\n",
    "        self._set_quantitative_features(reg_pattern,7,\"niveau_etude\", self._education_level_callback)\n",
    "    \n",
    "    def _education_level_callback(self, value):\n",
    "        bac_pattern = \"bac\\s*\\+\\s*[1-8]\"\n",
    "        result = re.compile(bac_pattern).search(value)\n",
    "        response = \"\"\n",
    "        if result:\n",
    "            response = re.findall('(\\d+)',value)\n",
    "            if response is not None:\n",
    "                return \"bac + \" + response[0] \n",
    "        \n",
    "        master_pattern = \"master\\s*(1|2)\"\n",
    "        result = re.compile(master_pattern).search(value)\n",
    "        if result:\n",
    "            response = re.findall('(\\d+)',value)\n",
    "            if response is not None:\n",
    "                return \"master \" + response[0] \n",
    "            \n",
    "        return value\n",
    "    \n",
    "    def set_type_de_cursus(self):\n",
    "        #j'ai desactivé le pattern \"|([(m|M)\\w+]aster?\\s?\\w{3,25})\" master car ça renvoie \"master dans\" ou \"master data\"\n",
    "        reg_pattern = '([(é|E)\\w+]cole [(i|I)\\w+]ngénieur?)|([(a|A)\\w+]utodidacte?)|([(g|G)\\w+]rande[s]? [(é|E)\\w+]cole[s]?)|([(é|E)\\w+]cole[s]? de [(c|C)\\w+]ommerce[s]?)|([(i|I)\\w+]ngénieur [(i|I)\\w+]nformatique?)'\n",
    "        self._set_quantitative_features(reg_pattern,8,\"type_de_cursus\", self._type_cursus_callback)\n",
    "    \n",
    "    def _type_cursus_callback(self, value):\n",
    "        ge_pattern = \"grandes?\\s*(é|e)coles?\"\n",
    "        result = re.compile(ge_pattern).search(value)\n",
    "        if result:\n",
    "            return \"grande école\"\n",
    "        \n",
    "        ec_pattern = \"([(é|E)\\w+]cole[s]? de [(c|C)\\w+]ommerce[s]?)\"\n",
    "        result = re.compile(ec_pattern).search(value)\n",
    "        if result:\n",
    "            return \"école de commerce\"\n",
    "        \n",
    "        return value\n",
    "        \n",
    "    def set_type_de_contrat(self):\n",
    "        #j'ai desactivé le pattern \"[(c|C)\\w+]ontrat?:?\\s\\w{3,25}|\"  car ça renovie \"contrat logue\", \"contrat avec\", etc\n",
    "        reg_pattern = '(cdi|cdd|stage|alternance|alternant|cdic|freelance)|3\\s*mois\\s*renouvelable\\s*'\n",
    "        self._set_quantitative_features(reg_pattern,9,\"type_de_contrat\", self._type_de_contrat_callback)\n",
    "    \n",
    "    def _type_de_contrat_callback(self,value):\n",
    "        bac_pattern = \"alternance|alternant\"\n",
    "        result = re.compile(bac_pattern).search(value)\n",
    "        if result:\n",
    "            return \"alternance\"\n",
    "        return value\n",
    "    \n",
    "    def set_grande_categorie(self):\n",
    "        reg_pattern = 'développeur?\\s*(web|mobile|data|front\\s*end|back\\s*end|desktop|full stack\\s*(developer))'\n",
    "        self._set_quantitative_features(reg_pattern,10,\"grande_categorie\",self._grande_categorie_callback)\n",
    "        \n",
    "    def _grande_categorie_callback(self, value):\n",
    "        bac_pattern = \"front\\s*end|back\\s*end\"\n",
    "        result = re.compile(bac_pattern).search(value)\n",
    "        if result:\n",
    "            if 'front' in value:\n",
    "                return \"front-end\"\n",
    "            else:\n",
    "                return \"back-end\"\n",
    "            \n",
    "        return value\n",
    "    \n",
    "    def _fusion_with_dataset(self, df):\n",
    "        diff_cols = list(OrderedSet(self.dataset.columns) - OrderedSet(df.columns))\n",
    "        self.dataset = self.dataset[diff_cols]\n",
    "        self.dataset = pd.concat([self.dataset,df], axis=1)\n",
    "    \n",
    "    def parse_langage(self):\n",
    "        languages = self.keyWordsProvider.get_langages()\n",
    "        \n",
    "        data = self._get_binnary_list_data(languages)\n",
    "        \n",
    "        language_dict = pd.DataFrame(data, columns=languages)\n",
    "        self.language_df = pd.DataFrame.from_dict(language_dict)\n",
    "\n",
    "        self._fusion_with_dataset(self.language_df)\n",
    "    \n",
    "    def parse_tools(self):\n",
    "        tools = self.keyWordsProvider.get_tools()\n",
    "        \n",
    "        data = self._get_binnary_list_data(tools)\n",
    "        tools_dict = pd.DataFrame(data, columns=tools)\n",
    "        self.tools_df = pd.DataFrame.from_dict(tools_dict)\n",
    "        self._fusion_with_dataset(self.tools_df)\n",
    "    \n",
    "    def set_salary_man(self):\n",
    "        salaire_moyen = []\n",
    "        for i in range(len(self.dataset)):\n",
    "            try:\n",
    "                salaire_liste = re.findall('(\\d+),?',normalize('NFKD',df['salaire'][i]).replace(' ',''))\n",
    "                mois = re.search('mois',df['salaire'][i])\n",
    "                if mois:\n",
    "                    if len(salaire_liste) > 1:\n",
    "                        moy = 12 * (int(salaire_liste[0]) + int(salaire_liste[1])) / 2\n",
    "                        salaire_moyen.append(moy)\n",
    "                    else:\n",
    "                        salaire_moyen.append(int(salaire_liste[0]) * 12)\n",
    "                else:\n",
    "                    if len(salaire_liste) > 1:\n",
    "                        moy = (int(salaire_liste[0]) + int(salaire_liste[1])) / 2\n",
    "                        if moy < 100:\n",
    "                            moy *= 1000\n",
    "                        salaire_moyen.append(moy)\n",
    "                    else:\n",
    "                        if int(salaire_liste[0]) < 100:\n",
    "                            salaire_moyen.append(int(salaire_liste[0]) * 1000)\n",
    "                        else:\n",
    "                            salaire_moyen.append(int(salaire_liste[0]))\n",
    "\n",
    "            except:\n",
    "                salaire_moyen.append(None)\n",
    "                continue\n",
    "        \n",
    "        label_col = \"salaire_moyen\"\n",
    "        \n",
    "        if (label_col not in self.dataset.columns):\n",
    "            self.dataset.insert(6, label_col,salaire_moyen,True)\n",
    "        else:\n",
    "            self.dataset[label_col] = pd.DataFrame(salaire_moyen)\n",
    "            self.dataset[label_col]\n",
    "    \n",
    "    def parse_salary_from_local_files(self):\n",
    "        index = 0\n",
    "        for root, dirs, files in os.walk(os.path.abspath(self.pages_path)):\n",
    "            for file in files:\n",
    "                local_file = os.path.join(root, file)\n",
    "                \n",
    "                with open(local_file,\"r\" ) as file:\n",
    "                    html = file.read() \n",
    "                    outer = re.compile(r'.*\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-')\n",
    "                    m = outer.search(html)\n",
    "                    if m is not None:\n",
    "                        link = m.group(0).replace(\"----------------\",\"\")\n",
    "                        dataset_index = self.dataset[self.dataset[\"URL\"] == link].index.values.astype(int)\n",
    "                        salary = self.dataset[\"salaire\"][dataset_index]\n",
    "                        if (len(salary.values) == 0):\n",
    "                            continue \n",
    "\n",
    "                        if (salary.values[0] != \"-\"):\n",
    "                            continue\n",
    "\n",
    "                        html = html.replace(m.group(0),\"\")\n",
    "                        soup = BeautifulSoup(html, \"html.parser\")\n",
    "                        result = soup.select(\".jobsearch-JobMetadataHeader-item\")\n",
    "                        if len(result) > 0:\n",
    "                            self.dataset[\"salaire\"][dataset_index] = self._get_salary(result)\n",
    "                            continue\n",
    "\n",
    "                        result = soup.select(\".jobsearch-JobMetadataHeader-itemWithIcon .jobsearch-JobMetadataHeader-iconLabel\")\n",
    "                        if len(result) > 0:\n",
    "                            self.dataset[\"salaire\"][dataset_index] = self._get_salary(result)\n",
    "                            continue\n",
    "\n",
    "                        result = soup.select(\"#jobDescriptionText\")\n",
    "                        if len(result) > 0:\n",
    "                            index = index + 1 \n",
    "                            outer_salary = re.compile(self.salary_pattern)\n",
    "                            m_salary = outer_salary.search(result[0].text)\n",
    "                            if m_salary is not None:\n",
    "                                salary = m_salary.group(0)\n",
    "                                print(salary)\n",
    "                                continue\n",
    "\n",
    "                        salary = np.nan #set nan if we cannot get value\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localIndeedPaser = LocalIndeedPaser()\n",
    "#localIndeedPaser.dataset[\"description\"].dropna(how='all').isna().sum()\n",
    "localIndeedPaser.dataset = localIndeedPaser.dataset.dropna(subset=['description'])\n",
    "localIndeedPaser.dataset[\"description\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localIndeedPaser.parse_education_level()\n",
    "localIndeedPaser.set_type_de_cursus()\n",
    "localIndeedPaser.set_type_de_contrat()\n",
    "localIndeedPaser.set_grande_categorie()\n",
    "localIndeedPaser.parse_langage()\n",
    "localIndeedPaser.parse_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localIndeedPaser.parse_salary_from_local_files()\n",
    "localIndeedPaser.set_salary_man()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localIndeedPaser.dataset[\"Date de publication\"].isna().sum()\n",
    "#localIndeedPaser.dataset[localIndeedPaser.dataset[\"Date de publication\"] == \"NaN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in localIndeedPaser.dataset.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install orderedset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localIndeedPaser.save_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xx = pd.read_csv(\"indeed.csv\")\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
