{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient \n",
    "import pandas as pd \n",
    "import json\n",
    "from pymongo import errors \n",
    "from django.core.validators import URLValidator\n",
    "from django.core.exceptions import ValidationError\n",
    "from pymongo.errors import BulkWriteError\n",
    "\n",
    "class IndeedMongodbDao:\n",
    "    def __init__(self):\n",
    "        self.conn = MongoClient() \n",
    "        self.db = self.conn.Indeed\n",
    "        self.collection = self.db.data\n",
    "        \n",
    "    def _valid_url_format(self,url):\n",
    "        val = URLValidator()\n",
    "        try:\n",
    "            val(url)\n",
    "        except ValidationError as e:\n",
    "            raise Exception('bad format for url {}'.format(ur))\n",
    "    \n",
    "    def insert_data_bulk(self,data):\n",
    "        try:\n",
    "            self.collection.insert_many(data)\n",
    "        except BulkWriteError as bwe:\n",
    "            print(bwe.details)\n",
    "            #you can also take this component and do more analysis\n",
    "            print(bwe.details['writeErrors'])\n",
    "            raise\n",
    "    \n",
    "    def insert_data(self, url, title, name, address, publication_date,salaire, description, localisation):\n",
    "        \n",
    "        try:\n",
    "            if url == \"\":\n",
    "                raise Exception('url cannot be empty {}'.format(ur))\n",
    "\n",
    "            self._valid_url_format(url)\n",
    "\n",
    "            if title == \"\":\n",
    "                raise Exception('title cannot be empty {}'.format(title))\n",
    "\n",
    "            if name == \"\":\n",
    "                raise Exception('the name of company cannot be be empty {}'.format(title))\n",
    "\n",
    "            if description == \"\":\n",
    "                raise Exception('description of company cannot be be empty {}'.format(title))\n",
    "\n",
    "            #URL,Titre,Nom entreprise,Adresse,Date de publication,salaire,description,localisation\n",
    "            line_to_insert = {\n",
    "                                \"url\": url,\n",
    "                                \"titre\":title,\n",
    "                                \"nom_entreprise\":name,\n",
    "                                \"adresse\":address,\n",
    "                                \"date_de_publication\":publication_date,\n",
    "                                \"salaire\":salaire,\n",
    "                                \"description\":description,\n",
    "                                \"localisation\":localisation\n",
    "                             }\n",
    "\n",
    "            # Insert Data \n",
    "            result = self.collection.insert_one(line_to_insert) \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        data = self.collection.find({})\n",
    "        return data\n",
    "    \n",
    "    def description_exist(self, description):\n",
    "        return self.collection.find({\"description\" : description}).count() > 0\n",
    "        \n",
    "    def url_exist(self, url):\n",
    "        return self.collection.find({\"url\" : url})\n",
    "\n",
    "    \n",
    "class Csv_MongodbMigratorTool:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dataset = pd.read_csv(\"archiv_to_mongo/indeed.part.1.csv\")\n",
    "        self.mongodbdao = IndeedMongodbDao()\n",
    "        \n",
    "    def bulk_migrate(self):\n",
    "        records = json.loads(self.dataset.T.to_json()).values()\n",
    "        self.mongodbdao.insert_data_bulk(records)\n",
    "    \n",
    "    def migrate(self):\n",
    "        for index, row in self.dataset.iterrows():\n",
    "            if self.mongodbdao.description_exist(row[\"description\"]) == False:\n",
    "                self.mongodbdao.insert_data(row[\"URL\"],row[\"Titre\"],row[\"Nom entreprise\"],row[\"Adresse\"],row[\"Date de publication\"],row[\"salaire\"], row[\"description\"], row[\"localisation\"])\n",
    "                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:70: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n"
     ]
    }
   ],
   "source": [
    "tool = Csv_MongodbMigratorTool()\n",
    "tool.migrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL\n",
      "Titre\n",
      "Nom entreprise\n",
      "Adresse\n",
      "Date de publication\n",
      "salaire\n",
      "description\n",
      "localisation\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"archiv_to_mongo/indeed.part.2.csv\")\n",
    "for index, row in df.iteritems():\n",
    "    print(index)\n",
    "\n",
    "#df.duplicated(subset=[\"URL\"], keep='first')\n",
    "#URL = df[\"URL\"]\n",
    "#df[URL.isin(URL[URL.duplicated()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
